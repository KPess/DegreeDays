{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 834,
   "id": "778d8022-686e-4c94-97f5-edba18938dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "id": "1054e409-1f25-48b0-aab0-5ade1936f2d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "id": "0c2bcd91-a1ca-42ec-937c-896df0c9dead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../SynMax/Population Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "id": "069cc539-c615-4a67-8348-444819ffac30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('../Synmax/Temperature Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfUScities = pd.read_csv('../Synmax/uscities.csv')\n",
    "\n",
    "#import from https://simplemaps.com/data/us-cities to check both dataframes against and sort into regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "id": "1b62fea8-b2bc-4c3b-8c63-e8f0c1c84cab",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            name station_code location_date  temp_mean_c  temp_min_c  \\\n",
       "0        Atlanta         KATL     4/20/2021    17.491667        12.2   \n",
       "1  Windsor Locks         KBDL     4/20/2021    13.887500         3.9   \n",
       "2      Nashville         KBNA     4/20/2021    15.175000         6.7   \n",
       "3          Boise         KBOI     4/20/2021     9.329167         1.7   \n",
       "4         Boston         KBOS     4/20/2021    16.716667        10.0   \n",
       "\n",
       "   temp_max_c  state  region  \n",
       "0        23.3    NaN     NaN  \n",
       "1        22.2    NaN     NaN  \n",
       "2        23.3    NaN     NaN  \n",
       "3        15.6    NaN     NaN  \n",
       "4        23.9    NaN     NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>station_code</th>\n      <th>location_date</th>\n      <th>temp_mean_c</th>\n      <th>temp_min_c</th>\n      <th>temp_max_c</th>\n      <th>state</th>\n      <th>region</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Atlanta</td>\n      <td>KATL</td>\n      <td>4/20/2021</td>\n      <td>17.491667</td>\n      <td>12.2</td>\n      <td>23.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Windsor Locks</td>\n      <td>KBDL</td>\n      <td>4/20/2021</td>\n      <td>13.887500</td>\n      <td>3.9</td>\n      <td>22.2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Nashville</td>\n      <td>KBNA</td>\n      <td>4/20/2021</td>\n      <td>15.175000</td>\n      <td>6.7</td>\n      <td>23.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Boise</td>\n      <td>KBOI</td>\n      <td>4/20/2021</td>\n      <td>9.329167</td>\n      <td>1.7</td>\n      <td>15.6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Boston</td>\n      <td>KBOS</td>\n      <td>4/20/2021</td>\n      <td>16.716667</td>\n      <td>10.0</td>\n      <td>23.9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 839
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a175c2-2c2b-4a55-b9e9-847458758669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "id": "01c33702-f375-4571-8184-1235f3a88a7b",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['City', 'State', 'population', 'Lon', 'Lat', 'region'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 840
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "id": "032be9d7-b6df-47e8-9c92-6da70258f880",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['name', 'station_code', 'location_date', 'temp_mean_c', 'temp_min_c',\n",
       "       'temp_max_c', 'state', 'region'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 841
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "id": "160827fa-97b2-43c4-a8cc-63739717ef13",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([['Henderson', 'Nevada', 260068, -115.0375, 36.0122, nan],\n",
       "       ['Manchester', 'New Hampshire', 109830, -71.4439, 42.9847, nan],\n",
       "       ['Elizabeth', 'New Jersey', 125660, -74.1935, 40.6663, nan],\n",
       "       ...,\n",
       "       ['Fort Lauderdale', 'Florida', 168528, -80.1439, 26.1413, nan],\n",
       "       ['Pompano Beach', 'Florida', 101617, -80.129, 26.2426, nan],\n",
       "       ['West Palm Beach', 'Florida', 101043, -80.1266, 26.7483, nan]],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 842
    }
   ],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "id": "1bf8d4ba-a69f-4dfb-8d70-ac10e7dcb812",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([['Atlanta', 'KATL', '4/20/2021', ..., 23.3, nan, nan],\n",
       "       ['Windsor Locks', 'KBDL', '4/20/2021', ..., 22.2, nan, nan],\n",
       "       ['Nashville', 'KBNA', '4/20/2021', ..., 23.3, nan, nan],\n",
       "       ...,\n",
       "       ['Raleigh/Durham', 'KRDU', '1/1/2015', ..., 10.6, nan, nan],\n",
       "       ['Pittsburgh', 'KPIT', '1/1/2015', ..., 1.7, nan, nan],\n",
       "       ['Phoenix/Sky HRBR', 'KPHX', '1/1/2015', ..., 7.2, nan, nan]],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 843
    }
   ],
   "source": [
    "df2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "c5cd52ee-e2d5-421a-a3a9-8367e3023f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2bydate = df2.groupby(['location_date', 'name'])[['temp_mean_c', 'temp_min_c', 'temp_max_c']].agg(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "ff870ee8-861b-4023-9ee8-2590a7528d1a",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                temp_mean_c  temp_min_c  temp_max_c\n",
       "location_date name                                                 \n",
       "1/1/2015      Albany              -3.362500        -7.2         0.0\n",
       "              Atlanta              6.758333         0.0        13.9\n",
       "              Baltimore           -0.345833        -7.8         6.1\n",
       "              Boise              -11.070833       -13.9        -8.0\n",
       "              Boston              -2.329167        -5.6         0.6\n",
       "...                                     ...         ...         ...\n",
       "9/9/2020      Spokane             17.358333         8.9        26.1\n",
       "              St Louis/Lambert    23.937500        19.4        29.4\n",
       "              Wash DC/Dulles      23.179167        20.0        26.1\n",
       "              Washington          24.229167        22.8        26.1\n",
       "              Windsor Locks       22.425000        18.3        27.8\n",
       "\n",
       "[86932 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>temp_mean_c</th>\n      <th>temp_min_c</th>\n      <th>temp_max_c</th>\n    </tr>\n    <tr>\n      <th>location_date</th>\n      <th>name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">1/1/2015</th>\n      <th>Albany</th>\n      <td>-3.362500</td>\n      <td>-7.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Atlanta</th>\n      <td>6.758333</td>\n      <td>0.0</td>\n      <td>13.9</td>\n    </tr>\n    <tr>\n      <th>Baltimore</th>\n      <td>-0.345833</td>\n      <td>-7.8</td>\n      <td>6.1</td>\n    </tr>\n    <tr>\n      <th>Boise</th>\n      <td>-11.070833</td>\n      <td>-13.9</td>\n      <td>-8.0</td>\n    </tr>\n    <tr>\n      <th>Boston</th>\n      <td>-2.329167</td>\n      <td>-5.6</td>\n      <td>0.6</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">9/9/2020</th>\n      <th>Spokane</th>\n      <td>17.358333</td>\n      <td>8.9</td>\n      <td>26.1</td>\n    </tr>\n    <tr>\n      <th>St Louis/Lambert</th>\n      <td>23.937500</td>\n      <td>19.4</td>\n      <td>29.4</td>\n    </tr>\n    <tr>\n      <th>Wash DC/Dulles</th>\n      <td>23.179167</td>\n      <td>20.0</td>\n      <td>26.1</td>\n    </tr>\n    <tr>\n      <th>Washington</th>\n      <td>24.229167</td>\n      <td>22.8</td>\n      <td>26.1</td>\n    </tr>\n    <tr>\n      <th>Windsor Locks</th>\n      <td>22.425000</td>\n      <td>18.3</td>\n      <td>27.8</td>\n    </tr>\n  </tbody>\n</table>\n<p>86932 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 845
    }
   ],
   "source": [
    "df2bydate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No of unique cities: 38\nCities: ['Atlanta', 'Windsor Locks', 'Nashville', 'Boise', 'Boston', 'Buffalo', 'Burbank', 'Baltimore', 'Columbus', 'Los Angeles', 'Covington', 'Washington', 'Denver', 'Dallas', 'Detroit/Wayne', 'Fresno', 'Spokane', 'Wash DC/Dulles', 'Houston', 'Las Vegas', 'NYC/LaGuardia', 'Little Rock', 'Memphis', 'Minneapolis', 'New Orleans', \"Chicago O'Hare\", 'Portland', 'Philadelphia', 'Phoenix/Sky HRBR', 'Pittsburgh', 'Raleigh/Durham', 'Richmond', 'Sacramento/Execu', 'Seattle', 'San Francisco', 'Salt Lake City', 'St Louis/Lambert', 'Albany']\n"
     ]
    }
   ],
   "source": [
    "# Check for unique cities in temp data\n",
    "cnt2 = 0\n",
    "cities2 = []\n",
    "for i in range(0, len(df2)):\n",
    "    if df2['name'][i] not in cities2:\n",
    "        cities2.append(df2['name'][i])\n",
    "        cnt2 += 1\n",
    "\n",
    "print(\"No of unique cities:\", cnt2)\n",
    "print(\"Cities:\", cities2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No of unique cities: 274\nCities: ['Henderson', 'Manchester', 'Elizabeth', 'Newark', 'Paterson', 'Jersey City', 'Albuquerque', 'Buffalo', 'Rochester', 'Syracuse', 'New York', 'Yonkers', 'Charlotte', 'Winston–Salem', 'High Point', 'Greensboro', 'Fayetteville', 'Durham', 'Cary', 'Raleigh', 'Wilmington', 'Fargo', 'Cincinnati', 'Dayton', 'Toledo', 'Columbus', 'Cleveland', 'Akron', 'Oklahoma City', 'Norman', 'Tulsa', 'Broken Arrow', 'Eugene', 'Salem', 'Portland', 'Gresham', 'Erie', 'Pittsburgh', 'Allentown', 'Philadelphia', 'Providence', 'Columbia', 'Charleston', 'Sioux Falls', 'Memphis', 'Clarksville', 'Nashville', 'Murfreesboro', 'Chattanooga', 'Knoxville', 'El Paso', 'Odessa', 'Midland', 'Lubbock', 'Amarillo', 'Abilene', 'Laredo', 'Wichita Falls', 'Killeen', 'Round Rock', 'Brownsville', 'Fort Worth', 'Waco', 'Corpus Christi', 'Denton', 'Arlington', 'Grand Prairie', 'Irving', 'Carrollton', 'Frisco', 'Dallas', 'Plano', 'Richardson', 'McKinney', 'Garland', 'Mesquite', 'Houston', 'Pasadena', 'Beaumont', 'West Valley City', 'West Jordan', 'Salt Lake City', 'Provo', 'Richmond', 'Alexandria', 'Newport News', 'Chesapeake', 'Hampton', 'Norfolk', 'Virginia Beach', 'Vancouver', 'Tacoma', 'Seattle', 'Kent', 'Everett', 'Bellevue', 'Spokane', 'Madison', 'Green Bay', 'Milwaukee', 'Costa Mesa', 'West Covina', 'Santa Ana', 'Orange', 'Irvine', 'Pomona', 'Anaheim', 'Ontario', 'Rancho Cucamonga', 'Corona', 'Fontana', 'Riverside', 'Rialto', 'Victorville', 'Oceanside', 'San Bernardino', 'Carlsbad', 'Moreno Valley', 'Murrieta', 'San Diego', 'Temecula', 'Escondido', 'Chula Vista', 'El Cajon', 'Lakewood', 'Arvada', 'Fort Collins', 'Westminster', 'Thornton', 'Denver', 'Centennial', 'Colorado Springs', 'Pueblo', 'Aurora', 'Stamford', 'Bridgeport', 'Atlanta', 'Athens', 'Augusta', 'Savannah', 'Honolulu', 'Boise', 'Springfield', 'Peoria', 'Rockford', 'Elgin', 'Naperville', 'Joliet', 'Chicago', 'Evansville', 'South Bend', 'Indianapolis', 'Fort Wayne', 'Des Moines', 'Cedar Rapids', 'Davenport', 'Wichita', 'Topeka', 'Olathe', 'Kansas City', 'Overland Park', 'Louisville', 'Lexington', 'Shreveport', 'Lafayette', 'Baton Rouge', 'New Orleans', 'Baltimore', 'Worcester', 'Lowell', 'Cambridge', 'Boston', 'Grand Rapids', 'Lansing', 'Ann Arbor', 'Flint', 'Detroit', 'Sterling Heights', 'Warren', 'Minneapolis', 'Saint Paul', 'Jackson', 'Independence', 'St. Louis', 'Billings', 'Lincoln', 'Omaha', 'Reno', 'Las Vegas', 'North Las Vegas', 'San Antonio', 'McAllen', 'Austin', 'Mobile', 'Birmingham', 'Huntsville', 'Montgomery', 'Anchorage', 'Surprise', 'Glendale', 'Phoenix', 'Tempe', 'Chandler', 'Scottsdale', 'Gilbert', 'Mesa', 'Tucson', 'Little Rock', 'San Francisco', 'Santa Rosa', 'Daly City', 'Berkeley', 'Vallejo', 'Oakland', 'Hayward', 'Fairfield', 'Sunnyvale', 'Concord', 'Santa Clara', 'Fremont', 'San Jose', 'Antioch', 'Salinas', 'Sacramento', 'Elk Grove', 'Stockton', 'Roseville', 'Modesto', 'Santa Maria', 'Fresno', 'Visalia', 'San Buenaventura (Ventura)', 'Oxnard', 'Bakersfield', 'Thousand Oaks', 'Simi Valley', 'Santa Clarita', 'Los Angeles', 'Inglewood', 'Torrance', 'Burbank', 'Lancaster', 'Long Beach', 'Downey', 'Palmdale', 'Norwalk', 'El Monte', 'Huntington Beach', 'Garden Grove', 'Fullerton', 'Waterbury', 'New Haven', 'Hartford', 'Washington', 'Tallahassee', 'Clearwater', 'Saint Petersburg', 'Tampa', 'Gainesville', 'Cape Coral', 'Jacksonville', 'Orlando', 'Palm Bay', 'Port Saint Lucie', 'Pembroke Pines', 'Miramar', 'Hialeah', 'Coral Springs', 'Miami Gardens', 'Miami', 'Hollywood', 'Fort Lauderdale', 'Pompano Beach', 'West Palm Beach']\n"
     ]
    }
   ],
   "source": [
    "# Check for unique cities in pop data\n",
    "cnt1 = 0\n",
    "cities1 = []\n",
    "for i in range(0, len(df)):\n",
    "    if df['City'][i] not in cities1:\n",
    "        cities1.append(df['City'][i])\n",
    "        cnt1 += 1\n",
    "\n",
    "print(\"No of unique cities:\", cnt1)\n",
    "print(\"Cities:\", cities1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "Pacific = ['Washington', 'Oregon', 'California', 'Hawaii', 'Alaska']\n",
    "Mountain = ['Montana', 'Idaho', 'Wyoming', 'Colorado', 'Utah', 'Nevada', 'Arizona', 'New Mexico']\n",
    "WestNorthCentral = ['North Dakota', 'South Dakota', 'Nebraska', 'Kansas', 'Minnesota', 'Iowa', 'Missouri']\n",
    "WestSouthCentral = ['Texas', 'Oklahoma', 'Arkansas', 'Louisiana']\n",
    "EastNorthCentral = ['Michigan', 'Wisconsin', 'Illinois', 'Indiana', 'Ohio']\n",
    "EastSouthCentral = ['Kentucky', 'Tennessee', 'Mississippi', 'Alabama']\n",
    "SouthAtlantic = ['Florida', 'Georgia', 'South Carolina', 'North Carolina', 'Virginia', 'West Virginia', 'Maryland', 'Delaware', 'District of Columbia']\n",
    "MidAtlantic = ['Pennsylvania', 'New York', 'New Jersey']\n",
    "NorthAtlantic = ['Maine', 'Vermont', 'New Hampshire', 'Massachusetts', 'Connecticut', 'Rhode Island']\n",
    "\n",
    "statecount = len(Pacific) + len(Mountain) + len(WestNorthCentral) + len(WestSouthCentral) + len(EastNorthCentral) + len(EastSouthCentral) + len(SouthAtlantic) + len(MidAtlantic) + len(NorthAtlantic)\n",
    "\n",
    "print(statecount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['Washington', 'Oregon', 'California', 'Hawaii', 'Alaska'], ['Montana', 'Idaho', 'Wyoming', 'Colorado', 'Utah', 'Nevada', 'Arizona', 'New Mexico'], ['North Dakota', 'South Dakota', 'Nebraska', 'Kansas', 'Minnesota', 'Iowa', 'Missouri'], ['Texas', 'Oklahoma', 'Arkansas', 'Louisiana'], ['Michigan', 'Wisconsin', 'Illinois', 'Indiana', 'Ohio'], ['Kentucky', 'Tennessee', 'Mississippi', 'Alabama'], ['Florida', 'Georgia', 'South Carolina', 'North Carolina', 'Virginia', 'West Virginia', 'Maryland', 'Delaware', 'District of Columbia'], ['Pennsylvania', 'New York', 'New Jersey'], ['Maine', 'Vermont', 'New Hampshire', 'Massachusetts', 'Connecticut', 'Rhode Island']]\n"
     ]
    }
   ],
   "source": [
    "regions = [Pacific, Mountain, WestNorthCentral, WestSouthCentral, EastNorthCentral, EastSouthCentral, SouthAtlantic, MidAtlantic, NorthAtlantic]\n",
    "print(regions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add boolean column indicating interpolated row\n",
    "# Weigh city temp entries by population versus entire region\n",
    "# Add missing dates to cities with temperature data in df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No of unique stations: 39\nStations: ['KATL', 'KBDL', 'KBNA', 'KBOI', 'KBOS', 'KBUF', 'KBUR', 'KBWI', 'KCMH', 'KCQT', 'KCVG', 'KDCA', 'KDEN', 'KDFW', 'KDTW', 'KFAT', 'KGEG', 'KIAD', 'KIAH', 'KLAS', 'KLGA', 'KLIT', 'KMEM', 'KMSP', 'KMSY', 'KORD', 'KPDX', 'KPHL', 'KPHX', 'KPIT', 'KPWM', 'KRDU', 'KRIC', 'KSAC', 'KSEA', 'KSFO', 'KSLC', 'KSTL', 'KALB']\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate city names with different station code - 39 stations 38 cities # KPDX Portland Oregon and KPWM Portland Maine\n",
    "cnt3 = 0\n",
    "stations = []\n",
    "for i in range(0, len(df2)):\n",
    "    if df2['station_code'][i] not in stations:\n",
    "        stations.append(df2['station_code'][i])\n",
    "        cnt3 += 1\n",
    "\n",
    "print(\"No of unique stations:\", cnt3)\n",
    "print(\"Stations:\", stations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign states to stations\n",
    "df2.loc[df2['station_code']== 'KBDL', ['state']] = 'Connecticut'\n",
    "df2.loc[df2['station_code']== 'KATL', ['state']] = 'Georgia'\n",
    "df2.loc[df2['station_code']== 'KBNA', ['state']] = 'Tennessee'\n",
    "df2.loc[df2['station_code']== 'KBOI', ['state']] = 'Idaho'\n",
    "df2.loc[df2['station_code']== 'KBOS', ['state']] = 'Massachusetts'\n",
    "df2.loc[df2['station_code']== 'KBUF', ['state']] = 'New York'\n",
    "df2.loc[df2['station_code']== 'KBUR', ['state']] = 'California'\n",
    "df2.loc[df2['station_code']== 'KBWI', ['state']] = 'Maryland'\n",
    "df2.loc[df2['station_code']== 'KCMH', ['state']] = 'Ohio'\n",
    "df2.loc[df2['station_code']== 'KCQT', ['state']] = 'California'\n",
    "df2.loc[df2['station_code']== 'KCVG', ['state']] = 'Kentucky'\n",
    "df2.loc[df2['station_code']== 'KDCA', ['state']] = 'Virginia'\n",
    "df2.loc[df2['station_code']== 'KDEN', ['state']] = 'Colorado'\n",
    "df2.loc[df2['station_code']== 'KDFW', ['state']] = 'Texas'\n",
    "df2.loc[df2['station_code']== 'KDTW', ['state']] = 'Michigan'\n",
    "df2.loc[df2['station_code']== 'KFAT', ['state']] = 'California'\n",
    "df2.loc[df2['station_code']== 'KGEG', ['state']] = 'Washington'\n",
    "df2.loc[df2['station_code']== 'KIAD', ['state']] = 'Virginia'\n",
    "df2.loc[df2['station_code']== 'KIAH', ['state']] = 'Texas'\n",
    "df2.loc[df2['station_code']== 'KLAS', ['state']] = 'Nevada'\n",
    "df2.loc[df2['station_code']== 'KLGA', ['state']] = 'New York'\n",
    "df2.loc[df2['station_code']== 'KLIT', ['state']] = 'Arkansas'\n",
    "df2.loc[df2['station_code']== 'KMEM', ['state']] = 'Tennessee'\n",
    "df2.loc[df2['station_code']== 'KMSP', ['state']] = 'Minnesota'\n",
    "df2.loc[df2['station_code']== 'KMSY', ['state']] = 'Louisiana'\n",
    "df2.loc[df2['station_code']== 'KORD', ['state']] = 'Illinois'\n",
    "df2.loc[df2['station_code']== 'KPDX', ['state']] = 'Oregon'\n",
    "df2.loc[df2['station_code']== 'KPHL', ['state']] = 'Pennsylvania'\n",
    "df2.loc[df2['station_code']== 'KPHX', ['state']] = 'Arizona'\n",
    "df2.loc[df2['station_code']== 'KPIT', ['state']] = 'Pennsylvania'\n",
    "df2.loc[df2['station_code']== 'KPWM', ['state']] = 'Maine'\n",
    "df2.loc[df2['station_code']== 'KRDU', ['state']] = 'North Carolina'\n",
    "df2.loc[df2['station_code']== 'KRIC', ['state']] = 'Virginia'\n",
    "df2.loc[df2['station_code']== 'KSAC', ['state']] = 'California'\n",
    "df2.loc[df2['station_code']== 'KSEA', ['state']] = 'Washington'\n",
    "df2.loc[df2['station_code']== 'KSFO', ['state']] = 'California'\n",
    "df2.loc[df2['station_code']== 'KSLC', ['state']] = 'Utah'\n",
    "df2.loc[df2['station_code']== 'KSTL', ['state']] = 'Missouri'\n",
    "df2.loc[df2['station_code']== 'KALB', ['state']] = 'New York'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Assign states to regions in temperature dataset\n",
    "\n",
    "region = []\n",
    "for i in range(0, len(df2)):\n",
    "    for j in range(0, len(regions)):\n",
    "        if df2['state'][i] in regions[j]:\n",
    "            region.append(j)\n",
    "# Establish region column in temp table      \n",
    "df2[\"region\"] = region  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign states to regions in population dataset\n",
    "\n",
    "region2 = []\n",
    "for k in range(0, len(df)):\n",
    "    for l in range(0, len(regions)):\n",
    "        if df['State'][k] in regions[l]:\n",
    "            region2.append(l)\n",
    "\n",
    "# Establish region column in pop table          \n",
    "df[\"region\"] = region2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'to_csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-867-5a9b7b0970f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'../SynMax/Temp Data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'../SynMax/Pop Data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf2bydate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'../SynMax/Pop Data by Date.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "df2.to_csv(path_or_buf='../SynMax/Temp Data.csv')\n",
    "df.to_csv(path_or_buf='../SynMax/Pop Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd0e96f6acdfbe39255c7875dee1b1acc7feafbd646fa220a924b021b041aac88e9",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}