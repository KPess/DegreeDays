{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 881,
   "id": "778d8022-686e-4c94-97f5-edba18938dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "id": "1054e409-1f25-48b0-aab0-5ade1936f2d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "id": "0c2bcd91-a1ca-42ec-937c-896df0c9dead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../SynMax/Population Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "id": "069cc539-c615-4a67-8348-444819ffac30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('../Synmax/Temperature Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfUScities = pd.read_csv('../Synmax/uscities.csv')\n",
    "\n",
    "#import from https://simplemaps.com/data/us-cities to check both dataframes against and sort into regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "id": "1b62fea8-b2bc-4c3b-8c63-e8f0c1c84cab",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            name station_code location_date  temp_mean_c  temp_min_c  \\\n",
       "0        Atlanta         KATL     4/20/2021    17.491667        12.2   \n",
       "1  Windsor Locks         KBDL     4/20/2021    13.887500         3.9   \n",
       "2      Nashville         KBNA     4/20/2021    15.175000         6.7   \n",
       "3          Boise         KBOI     4/20/2021     9.329167         1.7   \n",
       "4         Boston         KBOS     4/20/2021    16.716667        10.0   \n",
       "\n",
       "   temp_max_c  state  region  \n",
       "0        23.3    NaN     NaN  \n",
       "1        22.2    NaN     NaN  \n",
       "2        23.3    NaN     NaN  \n",
       "3        15.6    NaN     NaN  \n",
       "4        23.9    NaN     NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>station_code</th>\n      <th>location_date</th>\n      <th>temp_mean_c</th>\n      <th>temp_min_c</th>\n      <th>temp_max_c</th>\n      <th>state</th>\n      <th>region</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Atlanta</td>\n      <td>KATL</td>\n      <td>4/20/2021</td>\n      <td>17.491667</td>\n      <td>12.2</td>\n      <td>23.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Windsor Locks</td>\n      <td>KBDL</td>\n      <td>4/20/2021</td>\n      <td>13.887500</td>\n      <td>3.9</td>\n      <td>22.2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Nashville</td>\n      <td>KBNA</td>\n      <td>4/20/2021</td>\n      <td>15.175000</td>\n      <td>6.7</td>\n      <td>23.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Boise</td>\n      <td>KBOI</td>\n      <td>4/20/2021</td>\n      <td>9.329167</td>\n      <td>1.7</td>\n      <td>15.6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Boston</td>\n      <td>KBOS</td>\n      <td>4/20/2021</td>\n      <td>16.716667</td>\n      <td>10.0</td>\n      <td>23.9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 886
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a175c2-2c2b-4a55-b9e9-847458758669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "id": "01c33702-f375-4571-8184-1235f3a88a7b",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['City', 'State', 'population', 'Lon', 'Lat', 'region'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 887
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "id": "032be9d7-b6df-47e8-9c92-6da70258f880",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['name', 'station_code', 'location_date', 'temp_mean_c', 'temp_min_c',\n",
       "       'temp_max_c', 'state', 'region'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 888
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "id": "160827fa-97b2-43c4-a8cc-63739717ef13",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([['Henderson', 'Nevada', 260068, -115.0375, 36.0122, nan],\n",
       "       ['Manchester', 'New Hampshire', 109830, -71.4439, 42.9847, nan],\n",
       "       ['Elizabeth', 'New Jersey', 125660, -74.1935, 40.6663, nan],\n",
       "       ...,\n",
       "       ['Fort Lauderdale', 'Florida', 168528, -80.1439, 26.1413, nan],\n",
       "       ['Pompano Beach', 'Florida', 101617, -80.129, 26.2426, nan],\n",
       "       ['West Palm Beach', 'Florida', 101043, -80.1266, 26.7483, nan]],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 889
    }
   ],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "id": "1bf8d4ba-a69f-4dfb-8d70-ac10e7dcb812",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([['Atlanta', 'KATL', '4/20/2021', ..., 23.3, nan, nan],\n",
       "       ['Windsor Locks', 'KBDL', '4/20/2021', ..., 22.2, nan, nan],\n",
       "       ['Nashville', 'KBNA', '4/20/2021', ..., 23.3, nan, nan],\n",
       "       ...,\n",
       "       ['Raleigh/Durham', 'KRDU', '1/1/2015', ..., 10.6, nan, nan],\n",
       "       ['Pittsburgh', 'KPIT', '1/1/2015', ..., 1.7, nan, nan],\n",
       "       ['Phoenix/Sky HRBR', 'KPHX', '1/1/2015', ..., 7.2, nan, nan]],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 890
    }
   ],
   "source": [
    "df2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "id": "c5cd52ee-e2d5-421a-a3a9-8367e3023f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2bydate = df2.groupby(['location_date', 'name'])[['temp_mean_c', 'temp_min_c', 'temp_max_c']].agg(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "id": "ff870ee8-861b-4023-9ee8-2590a7528d1a",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                temp_mean_c  temp_min_c  temp_max_c\n",
       "location_date name                                                 \n",
       "1/1/2015      Albany              -3.362500        -7.2         0.0\n",
       "              Atlanta              6.758333         0.0        13.9\n",
       "              Baltimore           -0.345833        -7.8         6.1\n",
       "              Boise              -11.070833       -13.9        -8.0\n",
       "              Boston              -2.329167        -5.6         0.6\n",
       "...                                     ...         ...         ...\n",
       "9/9/2020      Spokane             17.358333         8.9        26.1\n",
       "              St Louis/Lambert    23.937500        19.4        29.4\n",
       "              Wash DC/Dulles      23.179167        20.0        26.1\n",
       "              Washington          24.229167        22.8        26.1\n",
       "              Windsor Locks       22.425000        18.3        27.8\n",
       "\n",
       "[86932 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>temp_mean_c</th>\n      <th>temp_min_c</th>\n      <th>temp_max_c</th>\n    </tr>\n    <tr>\n      <th>location_date</th>\n      <th>name</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">1/1/2015</th>\n      <th>Albany</th>\n      <td>-3.362500</td>\n      <td>-7.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Atlanta</th>\n      <td>6.758333</td>\n      <td>0.0</td>\n      <td>13.9</td>\n    </tr>\n    <tr>\n      <th>Baltimore</th>\n      <td>-0.345833</td>\n      <td>-7.8</td>\n      <td>6.1</td>\n    </tr>\n    <tr>\n      <th>Boise</th>\n      <td>-11.070833</td>\n      <td>-13.9</td>\n      <td>-8.0</td>\n    </tr>\n    <tr>\n      <th>Boston</th>\n      <td>-2.329167</td>\n      <td>-5.6</td>\n      <td>0.6</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">9/9/2020</th>\n      <th>Spokane</th>\n      <td>17.358333</td>\n      <td>8.9</td>\n      <td>26.1</td>\n    </tr>\n    <tr>\n      <th>St Louis/Lambert</th>\n      <td>23.937500</td>\n      <td>19.4</td>\n      <td>29.4</td>\n    </tr>\n    <tr>\n      <th>Wash DC/Dulles</th>\n      <td>23.179167</td>\n      <td>20.0</td>\n      <td>26.1</td>\n    </tr>\n    <tr>\n      <th>Washington</th>\n      <td>24.229167</td>\n      <td>22.8</td>\n      <td>26.1</td>\n    </tr>\n    <tr>\n      <th>Windsor Locks</th>\n      <td>22.425000</td>\n      <td>18.3</td>\n      <td>27.8</td>\n    </tr>\n  </tbody>\n</table>\n<p>86932 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 892
    }
   ],
   "source": [
    "df2bydate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No of unique cities: 38\nCities: ['Atlanta', 'Windsor Locks', 'Nashville', 'Boise', 'Boston', 'Buffalo', 'Burbank', 'Baltimore', 'Columbus', 'Los Angeles', 'Covington', 'Washington', 'Denver', 'Dallas', 'Detroit/Wayne', 'Fresno', 'Spokane', 'Wash DC/Dulles', 'Houston', 'Las Vegas', 'NYC/LaGuardia', 'Little Rock', 'Memphis', 'Minneapolis', 'New Orleans', \"Chicago O'Hare\", 'Portland', 'Philadelphia', 'Phoenix/Sky HRBR', 'Pittsburgh', 'Raleigh/Durham', 'Richmond', 'Sacramento/Execu', 'Seattle', 'San Francisco', 'Salt Lake City', 'St Louis/Lambert', 'Albany']\n"
     ]
    }
   ],
   "source": [
    "# Check for unique cities in temp data\n",
    "cnt2 = 0\n",
    "cities2 = []\n",
    "for i in range(0, len(df2)):\n",
    "    if df2['name'][i] not in cities2:\n",
    "        cities2.append(df2['name'][i])\n",
    "        cnt2 += 1\n",
    "\n",
    "print(\"No of unique cities:\", cnt2)\n",
    "print(\"Cities:\", cities2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No of unique cities: 274\nCities: ['Henderson', 'Manchester', 'Elizabeth', 'Newark', 'Paterson', 'Jersey City', 'Albuquerque', 'Buffalo', 'Rochester', 'Syracuse', 'New York', 'Yonkers', 'Charlotte', 'Winston–Salem', 'High Point', 'Greensboro', 'Fayetteville', 'Durham', 'Cary', 'Raleigh', 'Wilmington', 'Fargo', 'Cincinnati', 'Dayton', 'Toledo', 'Columbus', 'Cleveland', 'Akron', 'Oklahoma City', 'Norman', 'Tulsa', 'Broken Arrow', 'Eugene', 'Salem', 'Portland', 'Gresham', 'Erie', 'Pittsburgh', 'Allentown', 'Philadelphia', 'Providence', 'Columbia', 'Charleston', 'Sioux Falls', 'Memphis', 'Clarksville', 'Nashville', 'Murfreesboro', 'Chattanooga', 'Knoxville', 'El Paso', 'Odessa', 'Midland', 'Lubbock', 'Amarillo', 'Abilene', 'Laredo', 'Wichita Falls', 'Killeen', 'Round Rock', 'Brownsville', 'Fort Worth', 'Waco', 'Corpus Christi', 'Denton', 'Arlington', 'Grand Prairie', 'Irving', 'Carrollton', 'Frisco', 'Dallas', 'Plano', 'Richardson', 'McKinney', 'Garland', 'Mesquite', 'Houston', 'Pasadena', 'Beaumont', 'West Valley City', 'West Jordan', 'Salt Lake City', 'Provo', 'Richmond', 'Alexandria', 'Newport News', 'Chesapeake', 'Hampton', 'Norfolk', 'Virginia Beach', 'Vancouver', 'Tacoma', 'Seattle', 'Kent', 'Everett', 'Bellevue', 'Spokane', 'Madison', 'Green Bay', 'Milwaukee', 'Costa Mesa', 'West Covina', 'Santa Ana', 'Orange', 'Irvine', 'Pomona', 'Anaheim', 'Ontario', 'Rancho Cucamonga', 'Corona', 'Fontana', 'Riverside', 'Rialto', 'Victorville', 'Oceanside', 'San Bernardino', 'Carlsbad', 'Moreno Valley', 'Murrieta', 'San Diego', 'Temecula', 'Escondido', 'Chula Vista', 'El Cajon', 'Lakewood', 'Arvada', 'Fort Collins', 'Westminster', 'Thornton', 'Denver', 'Centennial', 'Colorado Springs', 'Pueblo', 'Aurora', 'Stamford', 'Bridgeport', 'Atlanta', 'Athens', 'Augusta', 'Savannah', 'Honolulu', 'Boise', 'Springfield', 'Peoria', 'Rockford', 'Elgin', 'Naperville', 'Joliet', 'Chicago', 'Evansville', 'South Bend', 'Indianapolis', 'Fort Wayne', 'Des Moines', 'Cedar Rapids', 'Davenport', 'Wichita', 'Topeka', 'Olathe', 'Kansas City', 'Overland Park', 'Louisville', 'Lexington', 'Shreveport', 'Lafayette', 'Baton Rouge', 'New Orleans', 'Baltimore', 'Worcester', 'Lowell', 'Cambridge', 'Boston', 'Grand Rapids', 'Lansing', 'Ann Arbor', 'Flint', 'Detroit', 'Sterling Heights', 'Warren', 'Minneapolis', 'Saint Paul', 'Jackson', 'Independence', 'St. Louis', 'Billings', 'Lincoln', 'Omaha', 'Reno', 'Las Vegas', 'North Las Vegas', 'San Antonio', 'McAllen', 'Austin', 'Mobile', 'Birmingham', 'Huntsville', 'Montgomery', 'Anchorage', 'Surprise', 'Glendale', 'Phoenix', 'Tempe', 'Chandler', 'Scottsdale', 'Gilbert', 'Mesa', 'Tucson', 'Little Rock', 'San Francisco', 'Santa Rosa', 'Daly City', 'Berkeley', 'Vallejo', 'Oakland', 'Hayward', 'Fairfield', 'Sunnyvale', 'Concord', 'Santa Clara', 'Fremont', 'San Jose', 'Antioch', 'Salinas', 'Sacramento', 'Elk Grove', 'Stockton', 'Roseville', 'Modesto', 'Santa Maria', 'Fresno', 'Visalia', 'San Buenaventura (Ventura)', 'Oxnard', 'Bakersfield', 'Thousand Oaks', 'Simi Valley', 'Santa Clarita', 'Los Angeles', 'Inglewood', 'Torrance', 'Burbank', 'Lancaster', 'Long Beach', 'Downey', 'Palmdale', 'Norwalk', 'El Monte', 'Huntington Beach', 'Garden Grove', 'Fullerton', 'Waterbury', 'New Haven', 'Hartford', 'Washington', 'Tallahassee', 'Clearwater', 'Saint Petersburg', 'Tampa', 'Gainesville', 'Cape Coral', 'Jacksonville', 'Orlando', 'Palm Bay', 'Port Saint Lucie', 'Pembroke Pines', 'Miramar', 'Hialeah', 'Coral Springs', 'Miami Gardens', 'Miami', 'Hollywood', 'Fort Lauderdale', 'Pompano Beach', 'West Palm Beach']\n"
     ]
    }
   ],
   "source": [
    "# Check for unique cities in pop data\n",
    "cnt1 = 0\n",
    "cities1 = []\n",
    "for i in range(0, len(df)):\n",
    "    if df['City'][i] not in cities1:\n",
    "        cities1.append(df['City'][i])\n",
    "        cnt1 += 1\n",
    "\n",
    "print(\"No of unique cities:\", cnt1)\n",
    "print(\"Cities:\", cities1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "Pacific = ['Washington', 'Oregon', 'California', 'Hawaii', 'Alaska']\n",
    "Mountain = ['Montana', 'Idaho', 'Wyoming', 'Colorado', 'Utah', 'Nevada', 'Arizona', 'New Mexico']\n",
    "WestNorthCentral = ['North Dakota', 'South Dakota', 'Nebraska', 'Kansas', 'Minnesota', 'Iowa', 'Missouri']\n",
    "WestSouthCentral = ['Texas', 'Oklahoma', 'Arkansas', 'Louisiana']\n",
    "EastNorthCentral = ['Michigan', 'Wisconsin', 'Illinois', 'Indiana', 'Ohio']\n",
    "EastSouthCentral = ['Kentucky', 'Tennessee', 'Mississippi', 'Alabama']\n",
    "SouthAtlantic = ['Florida', 'Georgia', 'South Carolina', 'North Carolina', 'Virginia', 'West Virginia', 'Maryland', 'Delaware', 'District of Columbia']\n",
    "MidAtlantic = ['Pennsylvania', 'New York', 'New Jersey']\n",
    "NorthAtlantic = ['Maine', 'Vermont', 'New Hampshire', 'Massachusetts', 'Connecticut', 'Rhode Island']\n",
    "\n",
    "statecount = len(Pacific) + len(Mountain) + len(WestNorthCentral) + len(WestSouthCentral) + len(EastNorthCentral) + len(EastSouthCentral) + len(SouthAtlantic) + len(MidAtlantic) + len(NorthAtlantic)\n",
    "\n",
    "print(statecount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['Washington', 'Oregon', 'California', 'Hawaii', 'Alaska'], ['Montana', 'Idaho', 'Wyoming', 'Colorado', 'Utah', 'Nevada', 'Arizona', 'New Mexico'], ['North Dakota', 'South Dakota', 'Nebraska', 'Kansas', 'Minnesota', 'Iowa', 'Missouri'], ['Texas', 'Oklahoma', 'Arkansas', 'Louisiana'], ['Michigan', 'Wisconsin', 'Illinois', 'Indiana', 'Ohio'], ['Kentucky', 'Tennessee', 'Mississippi', 'Alabama'], ['Florida', 'Georgia', 'South Carolina', 'North Carolina', 'Virginia', 'West Virginia', 'Maryland', 'Delaware', 'District of Columbia'], ['Pennsylvania', 'New York', 'New Jersey'], ['Maine', 'Vermont', 'New Hampshire', 'Massachusetts', 'Connecticut', 'Rhode Island']]\n"
     ]
    }
   ],
   "source": [
    "regions = [Pacific, Mountain, WestNorthCentral, WestSouthCentral, EastNorthCentral, EastSouthCentral, SouthAtlantic, MidAtlantic, NorthAtlantic]\n",
    "print(regions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to datetime and fill\n",
    "# Add boolean column indicating interpolated row\n",
    "# Weigh city temp entries by population versus entire region\n",
    "# Add missing dates to cities with temperature data in df2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No of unique stations: 39\nStations: ['KATL', 'KBDL', 'KBNA', 'KBOI', 'KBOS', 'KBUF', 'KBUR', 'KBWI', 'KCMH', 'KCQT', 'KCVG', 'KDCA', 'KDEN', 'KDFW', 'KDTW', 'KFAT', 'KGEG', 'KIAD', 'KIAH', 'KLAS', 'KLGA', 'KLIT', 'KMEM', 'KMSP', 'KMSY', 'KORD', 'KPDX', 'KPHL', 'KPHX', 'KPIT', 'KPWM', 'KRDU', 'KRIC', 'KSAC', 'KSEA', 'KSFO', 'KSLC', 'KSTL', 'KALB']\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate city names with different station code - 39 stations 38 cities # KPDX Portland Oregon and KPWM Portland Maine\n",
    "cnt3 = 0\n",
    "stations = []\n",
    "for i in range(0, len(df2)):\n",
    "    if df2['station_code'][i] not in stations:\n",
    "        stations.append(df2['station_code'][i])\n",
    "        cnt3 += 1\n",
    "\n",
    "print(\"No of unique stations:\", cnt3)\n",
    "print(\"Stations:\", stations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign states to stations\n",
    "df2.loc[df2['station_code']== 'KBDL', ['state']] = 'Connecticut'\n",
    "df2.loc[df2['station_code']== 'KATL', ['state']] = 'Georgia'\n",
    "df2.loc[df2['station_code']== 'KBNA', ['state']] = 'Tennessee'\n",
    "df2.loc[df2['station_code']== 'KBOI', ['state']] = 'Idaho'\n",
    "df2.loc[df2['station_code']== 'KBOS', ['state']] = 'Massachusetts'\n",
    "df2.loc[df2['station_code']== 'KBUF', ['state']] = 'New York'\n",
    "df2.loc[df2['station_code']== 'KBUR', ['state']] = 'California'\n",
    "df2.loc[df2['station_code']== 'KBWI', ['state']] = 'Maryland'\n",
    "df2.loc[df2['station_code']== 'KCMH', ['state']] = 'Ohio'\n",
    "df2.loc[df2['station_code']== 'KCQT', ['state']] = 'California'\n",
    "df2.loc[df2['station_code']== 'KCVG', ['state']] = 'Kentucky'\n",
    "df2.loc[df2['station_code']== 'KDCA', ['state']] = 'Virginia'\n",
    "df2.loc[df2['station_code']== 'KDEN', ['state']] = 'Colorado'\n",
    "df2.loc[df2['station_code']== 'KDFW', ['state']] = 'Texas'\n",
    "df2.loc[df2['station_code']== 'KDTW', ['state']] = 'Michigan'\n",
    "df2.loc[df2['station_code']== 'KFAT', ['state']] = 'California'\n",
    "df2.loc[df2['station_code']== 'KGEG', ['state']] = 'Washington'\n",
    "df2.loc[df2['station_code']== 'KIAD', ['state']] = 'Virginia'\n",
    "df2.loc[df2['station_code']== 'KIAH', ['state']] = 'Texas'\n",
    "df2.loc[df2['station_code']== 'KLAS', ['state']] = 'Nevada'\n",
    "df2.loc[df2['station_code']== 'KLGA', ['state']] = 'New York'\n",
    "df2.loc[df2['station_code']== 'KLIT', ['state']] = 'Arkansas'\n",
    "df2.loc[df2['station_code']== 'KMEM', ['state']] = 'Tennessee'\n",
    "df2.loc[df2['station_code']== 'KMSP', ['state']] = 'Minnesota'\n",
    "df2.loc[df2['station_code']== 'KMSY', ['state']] = 'Louisiana'\n",
    "df2.loc[df2['station_code']== 'KORD', ['state']] = 'Illinois'\n",
    "df2.loc[df2['station_code']== 'KPDX', ['state']] = 'Oregon'\n",
    "df2.loc[df2['station_code']== 'KPHL', ['state']] = 'Pennsylvania'\n",
    "df2.loc[df2['station_code']== 'KPHX', ['state']] = 'Arizona'\n",
    "df2.loc[df2['station_code']== 'KPIT', ['state']] = 'Pennsylvania'\n",
    "df2.loc[df2['station_code']== 'KPWM', ['state']] = 'Maine'\n",
    "df2.loc[df2['station_code']== 'KRDU', ['state']] = 'North Carolina'\n",
    "df2.loc[df2['station_code']== 'KRIC', ['state']] = 'Virginia'\n",
    "df2.loc[df2['station_code']== 'KSAC', ['state']] = 'California'\n",
    "df2.loc[df2['station_code']== 'KSEA', ['state']] = 'Washington'\n",
    "df2.loc[df2['station_code']== 'KSFO', ['state']] = 'California'\n",
    "df2.loc[df2['station_code']== 'KSLC', ['state']] = 'Utah'\n",
    "df2.loc[df2['station_code']== 'KSTL', ['state']] = 'Missouri'\n",
    "df2.loc[df2['station_code']== 'KALB', ['state']] = 'New York'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Assign states to regions in temperature dataset\n",
    "\n",
    "region = []\n",
    "for i in range(0, len(df2)):\n",
    "    for j in range(0, len(regions)):\n",
    "        if df2['state'][i] in regions[j]:\n",
    "            region.append(j)\n",
    "# Establish region column in temp table      \n",
    "df2[\"region\"] = region  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign states to regions in population dataset\n",
    "\n",
    "region2 = []\n",
    "for k in range(0, len(df)):\n",
    "    for l in range(0, len(regions)):\n",
    "        if df['State'][k] in regions[l]:\n",
    "            region2.append(l)\n",
    "\n",
    "# Establish region column in pop table          \n",
    "df[\"region\"] = region2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(path_or_buf='../SynMax/Temp Data.csv')\n",
    "df.to_csv(path_or_buf='../SynMax/Pop Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n               '2015-01-09', '2015-01-10',\n               ...\n               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n               '2021-04-19', '2021-04-20'],\n              dtype='datetime64[ns]', length=2302, freq='D')\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                name station_code        state  region       date  temp_mean_c\n",
       "0             Albany         KALB     New York       7 2015-01-01    -3.362500\n",
       "1             Albany         KALB     New York       7 2015-01-02    -0.683333\n",
       "2             Albany         KALB     New York       7 2015-01-03    -3.545833\n",
       "3             Albany         KALB     New York       7 2015-01-04     4.166667\n",
       "4             Albany         KALB     New York       7 2015-01-05    -4.654167\n",
       "...              ...          ...          ...     ...        ...          ...\n",
       "89214  Windsor Locks         KBDL  Connecticut       8 2021-04-16     3.883333\n",
       "89215  Windsor Locks         KBDL  Connecticut       8 2021-04-17     7.737500\n",
       "89216  Windsor Locks         KBDL  Connecticut       8 2021-04-18    11.487500\n",
       "89217  Windsor Locks         KBDL  Connecticut       8 2021-04-19    12.633333\n",
       "89218  Windsor Locks         KBDL  Connecticut       8 2021-04-20    13.887500\n",
       "\n",
       "[89219 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>station_code</th>\n      <th>state</th>\n      <th>region</th>\n      <th>date</th>\n      <th>temp_mean_c</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Albany</td>\n      <td>KALB</td>\n      <td>New York</td>\n      <td>7</td>\n      <td>2015-01-01</td>\n      <td>-3.362500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Albany</td>\n      <td>KALB</td>\n      <td>New York</td>\n      <td>7</td>\n      <td>2015-01-02</td>\n      <td>-0.683333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Albany</td>\n      <td>KALB</td>\n      <td>New York</td>\n      <td>7</td>\n      <td>2015-01-03</td>\n      <td>-3.545833</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Albany</td>\n      <td>KALB</td>\n      <td>New York</td>\n      <td>7</td>\n      <td>2015-01-04</td>\n      <td>4.166667</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Albany</td>\n      <td>KALB</td>\n      <td>New York</td>\n      <td>7</td>\n      <td>2015-01-05</td>\n      <td>-4.654167</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>89214</th>\n      <td>Windsor Locks</td>\n      <td>KBDL</td>\n      <td>Connecticut</td>\n      <td>8</td>\n      <td>2021-04-16</td>\n      <td>3.883333</td>\n    </tr>\n    <tr>\n      <th>89215</th>\n      <td>Windsor Locks</td>\n      <td>KBDL</td>\n      <td>Connecticut</td>\n      <td>8</td>\n      <td>2021-04-17</td>\n      <td>7.737500</td>\n    </tr>\n    <tr>\n      <th>89216</th>\n      <td>Windsor Locks</td>\n      <td>KBDL</td>\n      <td>Connecticut</td>\n      <td>8</td>\n      <td>2021-04-18</td>\n      <td>11.487500</td>\n    </tr>\n    <tr>\n      <th>89217</th>\n      <td>Windsor Locks</td>\n      <td>KBDL</td>\n      <td>Connecticut</td>\n      <td>8</td>\n      <td>2021-04-19</td>\n      <td>12.633333</td>\n    </tr>\n    <tr>\n      <th>89218</th>\n      <td>Windsor Locks</td>\n      <td>KBDL</td>\n      <td>Connecticut</td>\n      <td>8</td>\n      <td>2021-04-20</td>\n      <td>13.887500</td>\n    </tr>\n  </tbody>\n</table>\n<p>89219 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 907
    }
   ],
   "source": [
    "\n",
    "# Convert date to datetime and fill\n",
    "\n",
    "df2['date'] = pd.to_datetime(df2['location_date'])\n",
    "s=pd.date_range(df2.date.min(),df2.date.max(),freq='1 D')\n",
    "print(s)\n",
    "df3=df2.set_index(['name','station_code','state','region','date']).temp_mean_c.unstack().reindex(columns=s,fill_value='nan').stack().reset_index()\n",
    "df3.columns.values[4] = 'date'\n",
    "df3.columns.values[5] = 'temp_mean_c'\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0       2021-04-20\n75      2021-04-19\n78      2021-04-18\n153     2021-04-17\n156     2021-04-16\n           ...    \n89025   2015-01-05\n89100   2015-01-04\n89103   2015-01-03\n89178   2015-01-02\n89181   2015-01-01\nName: date, Length: 2287, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(df2.loc[df2['station_code'] == stations[0], 'date' ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "connect ECONNREFUSED 127.0.0.1:53724",
     "traceback": [
      "Error: connect ECONNREFUSED 127.0.0.1:53724",
      "at TCPConnectWrap.afterConnect [as oncomplete] (net.js:1146:16)"
     ]
    }
   ],
   "source": [
    "missingdates = {\"Station\": [], \"Date\": [] }\n",
    "#loop through each station\n",
    "for i in range(0, 1):\n",
    "    #loop through each date in s\n",
    "    for j in range(0, len(s)):\n",
    "    #check/create dates in individual station\n",
    "        if s[j] not in df2.loc[df2['station_code'] == stations[i], 'date']:\n",
    "            missingdates[\"Station\"].append(stations[i])\n",
    "            missingdates[\"Date\"].append(s[j].isoformat())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(missingdates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-922-87cb3b6a664a>, line 6)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-922-87cb3b6a664a>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    if s[j] not in df2.loc[df2['station_code'] == stations[i]]\u001b[0m\n\u001b[1;37m                                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#loop through each station\n",
    "for i in range(0, len(stations)):\n",
    "    #loop through each date in s\n",
    "    for j in range(0, len(s)):\n",
    "    #check/create dates in individual station\n",
    "        if s[j] not in df2.loc[df2['station_code'] == stations[i]]\n",
    "            df3=df2.set_index(['name','station_code','state','region','date']).temp_mean_c.unstack().reindex(columns=s,fill_value='nan').stack().reset_index()\n",
    "df3.columns.values[4] = 'date'\n",
    "df3.columns.values[5] = 'temp_mean_c'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Timestamp('2015-01-01 00:00:00', freq='D')"
      ]
     },
     "metadata": {},
     "execution_count": 914
    }
   ],
   "source": [
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0       2021-04-20\n",
       "75      2021-04-19\n",
       "78      2021-04-18\n",
       "153     2021-04-17\n",
       "156     2021-04-16\n",
       "           ...    \n",
       "89025   2015-01-05\n",
       "89100   2015-01-04\n",
       "89103   2015-01-03\n",
       "89178   2015-01-02\n",
       "89181   2015-01-01\n",
       "Name: date, Length: 2287, dtype: datetime64[ns]"
      ]
     },
     "metadata": {},
     "execution_count": 961
    }
   ],
   "source": [
    "df2.loc[df2['station_code']== stations[0], 'date'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "metadata": {},
     "execution_count": 964
    }
   ],
   "source": [
    "len(pd.date_range(start = '2015-01-01', end = '2021-04-20' ).difference(df2.loc[df2['station_code']== stations[0], 'date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd0e96f6acdfbe39255c7875dee1b1acc7feafbd646fa220a924b021b041aac88e9",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}