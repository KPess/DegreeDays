{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "778d8022-686e-4c94-97f5-edba18938dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1054e409-1f25-48b0-aab0-5ade1936f2d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0c2bcd91-a1ca-42ec-937c-896df0c9dead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import temperature and population files\n",
    "df = pd.read_csv('../SynMax/Population Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "069cc539-c615-4a67-8348-444819ffac30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import temperature and population files\n",
    "df2 = pd.read_csv('../Synmax/Temperature Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2015-01-01   NaN\n",
      "2015-01-02   NaN\n",
      "2015-01-03   NaN\n",
      "2015-01-04   NaN\n",
      "2015-01-05   NaN\n",
      "              ..\n",
      "2021-04-16   NaN\n",
      "2021-04-17   NaN\n",
      "2021-04-18   NaN\n",
      "2021-04-19   NaN\n",
      "2021-04-20   NaN\n",
      "Freq: D, Length: 2302, dtype: float64\n",
      "<ipython-input-88-55a513de126b>:3: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  s = pd.Series(index=time)\n"
     ]
    }
   ],
   "source": [
    "#Create time series including all relevant dates\n",
    "time = pd.date_range(start = '2015-01-01', end = '2021-04-20', freq='D' )\n",
    "s = pd.Series(index=time)\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import temperature and population files\n",
    "# Sanitize temp data\n",
    "    # Convert location_date to datetime\n",
    "    # Set datettime as index\n",
    "        # Iterate through stations one by one to find station's missing days\n",
    "            # Find missing days\n",
    "            # Iterate through missing dates\n",
    "                # Add date row\n",
    "                # Add other relevant info - station_code, region, etc\n",
    "                # Add boolean column indicating interpolated row\n",
    "                # Interpolate temperatures linearly from previous and next day from same station\n",
    "                # Weigh city temp entries by population versus entire region\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c5cd52ee-e2d5-421a-a3a9-8367e3023f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2bydate = df2.groupby(['location_date', 'name'])[['temp_mean_c', 'temp_min_c', 'temp_max_c']].agg(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime = pd.to_datetime(df2['location_date'])\n",
    "df2['date'] = datetime.dt.date\n",
    "df2 = df2.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No of unique cities: 38\nCities: ['Atlanta', 'Windsor Locks', 'Nashville', 'Boise', 'Boston', 'Buffalo', 'Burbank', 'Baltimore', 'Columbus', 'Los Angeles', 'Covington', 'Washington', 'Denver', 'Dallas', 'Detroit/Wayne', 'Fresno', 'Spokane', 'Wash DC/Dulles', 'Houston', 'Las Vegas', 'NYC/LaGuardia', 'Little Rock', 'Memphis', 'Minneapolis', 'New Orleans', \"Chicago O'Hare\", 'Portland', 'Philadelphia', 'Phoenix/Sky HRBR', 'Pittsburgh', 'Raleigh/Durham', 'Richmond', 'Sacramento/Execu', 'Seattle', 'San Francisco', 'Salt Lake City', 'St Louis/Lambert', 'Albany']\n"
     ]
    }
   ],
   "source": [
    "# Check for unique cities in temp data\n",
    "cnt2 = 0\n",
    "cities2 = []\n",
    "for i in range(0, len(df2)):\n",
    "    if df2['name'][i] not in cities2:\n",
    "        cities2.append(df2['name'][i])\n",
    "        cnt2 += 1\n",
    "\n",
    "print(\"No of unique cities:\", cnt2)\n",
    "print(\"Cities:\", cities2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No of unique cities: 274\nCities: ['Henderson', 'Manchester', 'Elizabeth', 'Newark', 'Paterson', 'Jersey City', 'Albuquerque', 'Buffalo', 'Rochester', 'Syracuse', 'New York', 'Yonkers', 'Charlotte', 'Winstonâ€“Salem', 'High Point', 'Greensboro', 'Fayetteville', 'Durham', 'Cary', 'Raleigh', 'Wilmington', 'Fargo', 'Cincinnati', 'Dayton', 'Toledo', 'Columbus', 'Cleveland', 'Akron', 'Oklahoma City', 'Norman', 'Tulsa', 'Broken Arrow', 'Eugene', 'Salem', 'Portland', 'Gresham', 'Erie', 'Pittsburgh', 'Allentown', 'Philadelphia', 'Providence', 'Columbia', 'Charleston', 'Sioux Falls', 'Memphis', 'Clarksville', 'Nashville', 'Murfreesboro', 'Chattanooga', 'Knoxville', 'El Paso', 'Odessa', 'Midland', 'Lubbock', 'Amarillo', 'Abilene', 'Laredo', 'Wichita Falls', 'Killeen', 'Round Rock', 'Brownsville', 'Fort Worth', 'Waco', 'Corpus Christi', 'Denton', 'Arlington', 'Grand Prairie', 'Irving', 'Carrollton', 'Frisco', 'Dallas', 'Plano', 'Richardson', 'McKinney', 'Garland', 'Mesquite', 'Houston', 'Pasadena', 'Beaumont', 'West Valley City', 'West Jordan', 'Salt Lake City', 'Provo', 'Richmond', 'Alexandria', 'Newport News', 'Chesapeake', 'Hampton', 'Norfolk', 'Virginia Beach', 'Vancouver', 'Tacoma', 'Seattle', 'Kent', 'Everett', 'Bellevue', 'Spokane', 'Madison', 'Green Bay', 'Milwaukee', 'Costa Mesa', 'West Covina', 'Santa Ana', 'Orange', 'Irvine', 'Pomona', 'Anaheim', 'Ontario', 'Rancho Cucamonga', 'Corona', 'Fontana', 'Riverside', 'Rialto', 'Victorville', 'Oceanside', 'San Bernardino', 'Carlsbad', 'Moreno Valley', 'Murrieta', 'San Diego', 'Temecula', 'Escondido', 'Chula Vista', 'El Cajon', 'Lakewood', 'Arvada', 'Fort Collins', 'Westminster', 'Thornton', 'Denver', 'Centennial', 'Colorado Springs', 'Pueblo', 'Aurora', 'Stamford', 'Bridgeport', 'Atlanta', 'Athens', 'Augusta', 'Savannah', 'Honolulu', 'Boise', 'Springfield', 'Peoria', 'Rockford', 'Elgin', 'Naperville', 'Joliet', 'Chicago', 'Evansville', 'South Bend', 'Indianapolis', 'Fort Wayne', 'Des Moines', 'Cedar Rapids', 'Davenport', 'Wichita', 'Topeka', 'Olathe', 'Kansas City', 'Overland Park', 'Louisville', 'Lexington', 'Shreveport', 'Lafayette', 'Baton Rouge', 'New Orleans', 'Baltimore', 'Worcester', 'Lowell', 'Cambridge', 'Boston', 'Grand Rapids', 'Lansing', 'Ann Arbor', 'Flint', 'Detroit', 'Sterling Heights', 'Warren', 'Minneapolis', 'Saint Paul', 'Jackson', 'Independence', 'St. Louis', 'Billings', 'Lincoln', 'Omaha', 'Reno', 'Las Vegas', 'North Las Vegas', 'San Antonio', 'McAllen', 'Austin', 'Mobile', 'Birmingham', 'Huntsville', 'Montgomery', 'Anchorage', 'Surprise', 'Glendale', 'Phoenix', 'Tempe', 'Chandler', 'Scottsdale', 'Gilbert', 'Mesa', 'Tucson', 'Little Rock', 'San Francisco', 'Santa Rosa', 'Daly City', 'Berkeley', 'Vallejo', 'Oakland', 'Hayward', 'Fairfield', 'Sunnyvale', 'Concord', 'Santa Clara', 'Fremont', 'San Jose', 'Antioch', 'Salinas', 'Sacramento', 'Elk Grove', 'Stockton', 'Roseville', 'Modesto', 'Santa Maria', 'Fresno', 'Visalia', 'San Buenaventura (Ventura)', 'Oxnard', 'Bakersfield', 'Thousand Oaks', 'Simi Valley', 'Santa Clarita', 'Los Angeles', 'Inglewood', 'Torrance', 'Burbank', 'Lancaster', 'Long Beach', 'Downey', 'Palmdale', 'Norwalk', 'El Monte', 'Huntington Beach', 'Garden Grove', 'Fullerton', 'Waterbury', 'New Haven', 'Hartford', 'Washington', 'Tallahassee', 'Clearwater', 'Saint Petersburg', 'Tampa', 'Gainesville', 'Cape Coral', 'Jacksonville', 'Orlando', 'Palm Bay', 'Port Saint Lucie', 'Pembroke Pines', 'Miramar', 'Hialeah', 'Coral Springs', 'Miami Gardens', 'Miami', 'Hollywood', 'Fort Lauderdale', 'Pompano Beach', 'West Palm Beach']\n"
     ]
    }
   ],
   "source": [
    "# Check for unique cities in pop data\n",
    "cnt1 = 0\n",
    "cities1 = []\n",
    "for i in range(0, len(df)):\n",
    "    if df['City'][i] not in cities1:\n",
    "        cities1.append(df['City'][i])\n",
    "        cnt1 += 1\n",
    "\n",
    "print(\"No of unique cities:\", cnt1)\n",
    "print(\"Cities:\", cities1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "Pacific = ['Washington', 'Oregon', 'California', 'Hawaii', 'Alaska']\n",
    "Mountain = ['Montana', 'Idaho', 'Wyoming', 'Colorado', 'Utah', 'Nevada', 'Arizona', 'New Mexico']\n",
    "WestNorthCentral = ['North Dakota', 'South Dakota', 'Nebraska', 'Kansas', 'Minnesota', 'Iowa', 'Missouri']\n",
    "WestSouthCentral = ['Texas', 'Oklahoma', 'Arkansas', 'Louisiana']\n",
    "EastNorthCentral = ['Michigan', 'Wisconsin', 'Illinois', 'Indiana', 'Ohio']\n",
    "EastSouthCentral = ['Kentucky', 'Tennessee', 'Mississippi', 'Alabama']\n",
    "SouthAtlantic = ['Florida', 'Georgia', 'South Carolina', 'North Carolina', 'Virginia', 'West Virginia', 'Maryland', 'Delaware', 'District of Columbia']\n",
    "MidAtlantic = ['Pennsylvania', 'New York', 'New Jersey']\n",
    "NorthAtlantic = ['Maine', 'Vermont', 'New Hampshire', 'Massachusetts', 'Connecticut', 'Rhode Island']\n",
    "\n",
    "statecount = len(Pacific) + len(Mountain) + len(WestNorthCentral) + len(WestSouthCentral) + len(EastNorthCentral) + len(EastSouthCentral) + len(SouthAtlantic) + len(MidAtlantic) + len(NorthAtlantic)\n",
    "\n",
    "print(statecount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['Washington', 'Oregon', 'California', 'Hawaii', 'Alaska'], ['Montana', 'Idaho', 'Wyoming', 'Colorado', 'Utah', 'Nevada', 'Arizona', 'New Mexico'], ['North Dakota', 'South Dakota', 'Nebraska', 'Kansas', 'Minnesota', 'Iowa', 'Missouri'], ['Texas', 'Oklahoma', 'Arkansas', 'Louisiana'], ['Michigan', 'Wisconsin', 'Illinois', 'Indiana', 'Ohio'], ['Kentucky', 'Tennessee', 'Mississippi', 'Alabama'], ['Florida', 'Georgia', 'South Carolina', 'North Carolina', 'Virginia', 'West Virginia', 'Maryland', 'Delaware', 'District of Columbia'], ['Pennsylvania', 'New York', 'New Jersey'], ['Maine', 'Vermont', 'New Hampshire', 'Massachusetts', 'Connecticut', 'Rhode Island']]\n"
     ]
    }
   ],
   "source": [
    "regions = [Pacific, Mountain, WestNorthCentral, WestSouthCentral, EastNorthCentral, EastSouthCentral, SouthAtlantic, MidAtlantic, NorthAtlantic]\n",
    "print(regions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No of unique stations: 39\nStations: ['KATL', 'KBDL', 'KBNA', 'KBOI', 'KBOS', 'KBUF', 'KBUR', 'KBWI', 'KCMH', 'KCQT', 'KCVG', 'KDCA', 'KDEN', 'KDFW', 'KDTW', 'KFAT', 'KGEG', 'KIAD', 'KIAH', 'KLAS', 'KLGA', 'KLIT', 'KMEM', 'KMSP', 'KMSY', 'KORD', 'KPDX', 'KPHL', 'KPHX', 'KPIT', 'KPWM', 'KRDU', 'KRIC', 'KSAC', 'KSEA', 'KSFO', 'KSLC', 'KSTL', 'KALB']\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate city names with different station code - 39 stations 38 cities # KPDX Portland Oregon and KPWM Portland Maine\n",
    "cnt3 = 0\n",
    "stations = []\n",
    "for i in range(0, len(df2)):\n",
    "    if df2['station_code'][i] not in stations:\n",
    "        stations.append(df2['station_code'][i])\n",
    "        cnt3 += 1\n",
    "\n",
    "print(\"No of unique stations:\", cnt3)\n",
    "print(\"Stations:\", stations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign states to stations\n",
    "df2.loc[df2['station_code']== 'KBDL', ['state']] = 'Connecticut'\n",
    "df2.loc[df2['station_code']== 'KATL', ['state']] = 'Georgia'\n",
    "df2.loc[df2['station_code']== 'KBNA', ['state']] = 'Tennessee'\n",
    "df2.loc[df2['station_code']== 'KBOI', ['state']] = 'Idaho'\n",
    "df2.loc[df2['station_code']== 'KBOS', ['state']] = 'Massachusetts'\n",
    "df2.loc[df2['station_code']== 'KBUF', ['state']] = 'New York'\n",
    "df2.loc[df2['station_code']== 'KBUR', ['state']] = 'California'\n",
    "df2.loc[df2['station_code']== 'KBWI', ['state']] = 'Maryland'\n",
    "df2.loc[df2['station_code']== 'KCMH', ['state']] = 'Ohio'\n",
    "df2.loc[df2['station_code']== 'KCQT', ['state']] = 'California'\n",
    "df2.loc[df2['station_code']== 'KCVG', ['state']] = 'Kentucky'\n",
    "df2.loc[df2['station_code']== 'KDCA', ['state']] = 'Virginia'\n",
    "df2.loc[df2['station_code']== 'KDEN', ['state']] = 'Colorado'\n",
    "df2.loc[df2['station_code']== 'KDFW', ['state']] = 'Texas'\n",
    "df2.loc[df2['station_code']== 'KDTW', ['state']] = 'Michigan'\n",
    "df2.loc[df2['station_code']== 'KFAT', ['state']] = 'California'\n",
    "df2.loc[df2['station_code']== 'KGEG', ['state']] = 'Washington'\n",
    "df2.loc[df2['station_code']== 'KIAD', ['state']] = 'Virginia'\n",
    "df2.loc[df2['station_code']== 'KIAH', ['state']] = 'Texas'\n",
    "df2.loc[df2['station_code']== 'KLAS', ['state']] = 'Nevada'\n",
    "df2.loc[df2['station_code']== 'KLGA', ['state']] = 'New York'\n",
    "df2.loc[df2['station_code']== 'KLIT', ['state']] = 'Arkansas'\n",
    "df2.loc[df2['station_code']== 'KMEM', ['state']] = 'Tennessee'\n",
    "df2.loc[df2['station_code']== 'KMSP', ['state']] = 'Minnesota'\n",
    "df2.loc[df2['station_code']== 'KMSY', ['state']] = 'Louisiana'\n",
    "df2.loc[df2['station_code']== 'KORD', ['state']] = 'Illinois'\n",
    "df2.loc[df2['station_code']== 'KPDX', ['state']] = 'Oregon'\n",
    "df2.loc[df2['station_code']== 'KPHL', ['state']] = 'Pennsylvania'\n",
    "df2.loc[df2['station_code']== 'KPHX', ['state']] = 'Arizona'\n",
    "df2.loc[df2['station_code']== 'KPIT', ['state']] = 'Pennsylvania'\n",
    "df2.loc[df2['station_code']== 'KPWM', ['state']] = 'Maine'\n",
    "df2.loc[df2['station_code']== 'KRDU', ['state']] = 'North Carolina'\n",
    "df2.loc[df2['station_code']== 'KRIC', ['state']] = 'Virginia'\n",
    "df2.loc[df2['station_code']== 'KSAC', ['state']] = 'California'\n",
    "df2.loc[df2['station_code']== 'KSEA', ['state']] = 'Washington'\n",
    "df2.loc[df2['station_code']== 'KSFO', ['state']] = 'California'\n",
    "df2.loc[df2['station_code']== 'KSLC', ['state']] = 'Utah'\n",
    "df2.loc[df2['station_code']== 'KSTL', ['state']] = 'Missouri'\n",
    "df2.loc[df2['station_code']== 'KALB', ['state']] = 'New York'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Assign states to regions in temperature dataset\n",
    "\n",
    "region = []\n",
    "for i in range(0, len(df2)):\n",
    "    for j in range(0, len(regions)):\n",
    "        if df2['state'][i] in regions[j]:\n",
    "            region.append(j)\n",
    "# Establish region column in temp table      \n",
    "df2[\"region\"] = region  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign states to regions in population dataset\n",
    "\n",
    "region2 = []\n",
    "for k in range(0, len(df)):\n",
    "    for l in range(0, len(regions)):\n",
    "        if df['State'][k] in regions[l]:\n",
    "            region2.append(l)\n",
    "\n",
    "# Establish region column in pop table          \n",
    "df[\"region\"] = region2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframes as .csv\n",
    "df2.to_csv(path_or_buf='../SynMax/Temp Data.csv')\n",
    "df.to_csv(path_or_buf='../SynMax/Pop Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                        name station_code location_date  temp_mean_c  \\\ndate                                                                   \n2021-04-20           Atlanta         KATL     4/20/2021    17.491667   \n2021-04-20     Windsor Locks         KBDL     4/20/2021    13.887500   \n2021-04-20         Nashville         KBNA     4/20/2021    15.175000   \n2021-04-20             Boise         KBOI     4/20/2021     9.329167   \n2021-04-20            Boston         KBOS     4/20/2021    16.716667   \n...                      ...          ...           ...          ...   \n2015-01-01  Sacramento/Execu         KSAC      1/1/2015     3.500000   \n2015-01-01          Portland         KPWM      1/1/2015    -3.454167   \n2015-01-01    Raleigh/Durham         KRDU      1/1/2015     3.291667   \n2015-01-01        Pittsburgh         KPIT      1/1/2015    -2.570833   \n2015-01-01  Phoenix/Sky HRBR         KPHX      1/1/2015     4.354167   \n\n            temp_min_c  temp_max_c           state  region  \ndate                                                        \n2021-04-20        12.2        23.3         Georgia       6  \n2021-04-20         3.9        22.2     Connecticut       8  \n2021-04-20         6.7        23.3       Tennessee       5  \n2021-04-20         1.7        15.6           Idaho       1  \n2021-04-20        10.0        23.9   Massachusetts       8  \n...                ...         ...             ...     ...  \n2015-01-01        -1.7        10.6      California       0  \n2015-01-01        -7.8        -0.6           Maine       8  \n2015-01-01        -4.4        10.6  North Carolina       6  \n2015-01-01        -6.7         1.7    Pennsylvania       7  \n2015-01-01         1.7         7.2         Arizona       1  \n\n[89219 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert date to datetime and fill\n",
    "datetime = pd.to_datetime(df2['location_date'])\n",
    "df2['date'] = datetime.dt.date\n",
    "df2 = df2.set_index(\"date\")\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n",
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
      "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
      "               '2015-01-09', '2015-01-10',\n",
      "               ...\n",
      "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
      "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
      "               '2021-04-19', '2021-04-20'],\n",
      "              dtype='datetime64[ns]', length=2302, freq=None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "allmissingdays = []\n",
    "#loop through each station\n",
    "for i in range(0, len(stations)):\n",
    "    missingFromStation = pd.date_range(start = '2015-01-01', end = '2021-04-20' ).difference(df2.loc[df2['station_code']== stations[i]])\n",
    "\n",
    "    allmissingdays.append(missingFromStation) \n",
    "    print(missingFromStation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n",
       "               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n",
       "               '2015-01-09', '2015-01-10',\n",
       "               ...\n",
       "               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n",
       "               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n",
       "               '2021-04-19', '2021-04-20'],\n",
       "              dtype='datetime64[ns]', length=2302, freq=None)"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "pd.date_range(start = '2015-01-01', end = '2021-04-20' ).difference(df2.loc[df2['station_code']== stations[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'date'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-90218c7e8106>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmissingdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmissingdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'2015-01-01'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'2021-04-20'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'station_code'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m \u001b[0mstations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m#loop through each date in s\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    887\u001b[0m                     \u001b[1;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1060\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1061\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m         \u001b[1;31m# no multi-index, so validate all of the indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    805\u001b[0m                 \u001b[1;31m# We don't need to check for tuples here because those are\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m                 \u001b[1;31m#  caught by the _is_nested_tuple_indexer check above.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m                 \u001b[0msection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[1;31m# We should never have a scalar section here, because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1071\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m         \u001b[1;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1073\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mxs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3722\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3723\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3724\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3725\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "\n",
    "#loop through each station\n",
    "for i in range(0, len(stations)):\n",
    "    missingdates = []\n",
    "    missingdates = pd.date_range(start = '2015-01-01', end = '2021-04-20' ).difference(df2.loc[df2['station_code']== stations[i], 'date'])\n",
    "    #loop through each date in s\n",
    "    for j in range(0, len(s)):\n",
    "    #check/create dates in individual station\n",
    "        if s[j] not in df2.loc[df2['station_code'] == stations[0], 'date']:\n",
    "            missingdates[\"Station\"].append(stations[0])\n",
    "            missingdates[\"Date\"].append(s[j].isoformat())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total number of missing days by station code - KPHX has no missing days \n",
    "missingCount = 0\n",
    "\n",
    "for i in range(0, len(stations)):\n",
    "    ct1 = len(pd.date_range(start = '2015-01-01', end = '2021-04-20' ).difference(df2.loc[df2['station_code']== stations[i], 'date']))\n",
    "    missingCount += ct1\n",
    "\n",
    "print(missingCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                        name station_code location_date  temp_mean_c  \\\n",
       "date                                                                   \n",
       "2021-04-20           Atlanta         KATL     4/20/2021    17.491667   \n",
       "2021-04-20     Windsor Locks         KBDL     4/20/2021    13.887500   \n",
       "2021-04-20         Nashville         KBNA     4/20/2021    15.175000   \n",
       "2021-04-20             Boise         KBOI     4/20/2021     9.329167   \n",
       "2021-04-20            Boston         KBOS     4/20/2021    16.716667   \n",
       "...                      ...          ...           ...          ...   \n",
       "2015-01-01  Sacramento/Execu         KSAC      1/1/2015     3.500000   \n",
       "2015-01-01          Portland         KPWM      1/1/2015    -3.454167   \n",
       "2015-01-01    Raleigh/Durham         KRDU      1/1/2015     3.291667   \n",
       "2015-01-01        Pittsburgh         KPIT      1/1/2015    -2.570833   \n",
       "2015-01-01  Phoenix/Sky HRBR         KPHX      1/1/2015     4.354167   \n",
       "\n",
       "            temp_min_c  temp_max_c           state  region  \n",
       "date                                                        \n",
       "2021-04-20        12.2        23.3         Georgia       6  \n",
       "2021-04-20         3.9        22.2     Connecticut       8  \n",
       "2021-04-20         6.7        23.3       Tennessee       5  \n",
       "2021-04-20         1.7        15.6           Idaho       1  \n",
       "2021-04-20        10.0        23.9   Massachusetts       8  \n",
       "...                ...         ...             ...     ...  \n",
       "2015-01-01        -1.7        10.6      California       0  \n",
       "2015-01-01        -7.8        -0.6           Maine       8  \n",
       "2015-01-01        -4.4        10.6  North Carolina       6  \n",
       "2015-01-01        -6.7         1.7    Pennsylvania       7  \n",
       "2015-01-01         1.7         7.2         Arizona       1  \n",
       "\n",
       "[89219 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>station_code</th>\n      <th>location_date</th>\n      <th>temp_mean_c</th>\n      <th>temp_min_c</th>\n      <th>temp_max_c</th>\n      <th>state</th>\n      <th>region</th>\n    </tr>\n    <tr>\n      <th>date</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2021-04-20</th>\n      <td>Atlanta</td>\n      <td>KATL</td>\n      <td>4/20/2021</td>\n      <td>17.491667</td>\n      <td>12.2</td>\n      <td>23.3</td>\n      <td>Georgia</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2021-04-20</th>\n      <td>Windsor Locks</td>\n      <td>KBDL</td>\n      <td>4/20/2021</td>\n      <td>13.887500</td>\n      <td>3.9</td>\n      <td>22.2</td>\n      <td>Connecticut</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2021-04-20</th>\n      <td>Nashville</td>\n      <td>KBNA</td>\n      <td>4/20/2021</td>\n      <td>15.175000</td>\n      <td>6.7</td>\n      <td>23.3</td>\n      <td>Tennessee</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2021-04-20</th>\n      <td>Boise</td>\n      <td>KBOI</td>\n      <td>4/20/2021</td>\n      <td>9.329167</td>\n      <td>1.7</td>\n      <td>15.6</td>\n      <td>Idaho</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2021-04-20</th>\n      <td>Boston</td>\n      <td>KBOS</td>\n      <td>4/20/2021</td>\n      <td>16.716667</td>\n      <td>10.0</td>\n      <td>23.9</td>\n      <td>Massachusetts</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2015-01-01</th>\n      <td>Sacramento/Execu</td>\n      <td>KSAC</td>\n      <td>1/1/2015</td>\n      <td>3.500000</td>\n      <td>-1.7</td>\n      <td>10.6</td>\n      <td>California</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2015-01-01</th>\n      <td>Portland</td>\n      <td>KPWM</td>\n      <td>1/1/2015</td>\n      <td>-3.454167</td>\n      <td>-7.8</td>\n      <td>-0.6</td>\n      <td>Maine</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2015-01-01</th>\n      <td>Raleigh/Durham</td>\n      <td>KRDU</td>\n      <td>1/1/2015</td>\n      <td>3.291667</td>\n      <td>-4.4</td>\n      <td>10.6</td>\n      <td>North Carolina</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2015-01-01</th>\n      <td>Pittsburgh</td>\n      <td>KPIT</td>\n      <td>1/1/2015</td>\n      <td>-2.570833</td>\n      <td>-6.7</td>\n      <td>1.7</td>\n      <td>Pennsylvania</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2015-01-01</th>\n      <td>Phoenix/Sky HRBR</td>\n      <td>KPHX</td>\n      <td>1/1/2015</td>\n      <td>4.354167</td>\n      <td>1.7</td>\n      <td>7.2</td>\n      <td>Arizona</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>89219 rows Ã— 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DatetimeIndex(['2015-01-01', '2015-01-02', '2015-01-03', '2015-01-04',\n               '2015-01-05', '2015-01-06', '2015-01-07', '2015-01-08',\n               '2015-01-09', '2015-01-10',\n               ...\n               '2021-04-11', '2021-04-12', '2021-04-13', '2021-04-14',\n               '2021-04-15', '2021-04-16', '2021-04-17', '2021-04-18',\n               '2021-04-19', '2021-04-20'],\n              dtype='datetime64[ns]', length=2302, freq=None)\n"
     ]
    }
   ],
   "source": [
    "print(pd.date_range(start = '2015-01-01', end = '2021-04-20' ).difference(df2.loc[df2['station_code']== stations[28], 'location_date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'date'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-d1dda8b106d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmissingFromStation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'2015-01-01'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'2021-04-20'\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'station_code'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m \u001b[0mstations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissingFromStation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    887\u001b[0m                     \u001b[1;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1060\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1061\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m         \u001b[1;31m# no multi-index, so validate all of the indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    805\u001b[0m                 \u001b[1;31m# We don't need to check for tuples here because those are\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m                 \u001b[1;31m#  caught by the _is_nested_tuple_indexer check above.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m                 \u001b[0msection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[1;31m# We should never have a scalar section here, because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1071\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m         \u001b[1;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1073\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1075\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mxs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3722\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3723\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3724\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3725\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "missingFromStation = pd.date_range(start = '2015-01-01', end = '2021-04-20' ).difference(df2.loc[df2['station_code']== stations[0], 'date'])\n",
    "\n",
    "print(missingFromStation[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missingFromStation = []\n",
    "newFrame = []\n",
    "df5 = []\n",
    "\n",
    "# Create loop for all stations\n",
    "\n",
    "for i in range(0, len(stations)):\n",
    "    missingFromStation = pd.date_range(start = '2015-01-01', end = '2021-04-20' ).difference(df2.loc[df2['station_code']== stations[i], 'date'])\n",
    "    \n",
    "# Within each station create a new frame including only missing dates and station code\n",
    "    newFrame = pd.DataFrame({'date': missingFromStation.date, 'station_code': stations[i]})\n",
    "    print(newFrame)\n",
    "# Merge new frame with df2 (ignoring index?)\n",
    "    df5 = df2.append(newFrame, ignore_index=True)\n",
    "    print(len(df5))\n",
    "\n",
    "#Use for loop to create an array of stations\n",
    "stations\n",
    "df5.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "               name station_code location_date  temp_mean_c  temp_min_c  \\\ndate                                                                      \n2021-04-20  Atlanta         KATL     4/20/2021    17.491667        12.2   \n2021-04-19  Atlanta         KATL     4/19/2021    16.154167        11.1   \n2021-04-18  Atlanta         KATL     4/18/2021    16.720833        11.7   \n2021-04-17  Atlanta         KATL     4/17/2021    16.795833        12.8   \n2021-04-16  Atlanta         KATL     4/16/2021    14.695833        10.0   \n...             ...          ...           ...          ...         ...   \n2015-01-05  Atlanta         KATL      1/5/2015     5.045833         1.1   \n2015-01-04  Atlanta         KATL      1/4/2015    14.279167         6.7   \n2015-01-03  Atlanta         KATL      1/3/2015    11.154167         8.9   \n2015-01-02  Atlanta         KATL      1/2/2015     8.116667         6.7   \n2015-01-01  Atlanta         KATL      1/1/2015     6.758333         0.0   \n\n            temp_max_c    state  region  \ndate                                     \n2021-04-20        23.3  Georgia       6  \n2021-04-19        21.7  Georgia       6  \n2021-04-18        22.2  Georgia       6  \n2021-04-17        21.7  Georgia       6  \n2021-04-16        19.4  Georgia       6  \n...                ...      ...     ...  \n2015-01-05         8.9  Georgia       6  \n2015-01-04        17.8  Georgia       6  \n2015-01-03        16.1  Georgia       6  \n2015-01-02         9.4  Georgia       6  \n2015-01-01        13.9  Georgia       6  \n\n[2287 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create sub-frame of specific station\n",
    "KATL = df2.loc[df2['station_code'] == stations[0]]\n",
    "print(KATL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "               name station_code location_date  temp_mean_c  temp_min_c  \\\n",
      "date                                                                      \n",
      "2021-04-20  Atlanta         KATL     4/20/2021    17.491667        12.2   \n",
      "2021-04-19  Atlanta         KATL     4/19/2021    16.154167        11.1   \n",
      "2021-04-18  Atlanta         KATL     4/18/2021    16.720833        11.7   \n",
      "2021-04-17  Atlanta         KATL     4/17/2021    16.795833        12.8   \n",
      "2021-04-16  Atlanta         KATL     4/16/2021    14.695833        10.0   \n",
      "...             ...          ...           ...          ...         ...   \n",
      "2015-01-05  Atlanta         KATL      1/5/2015     5.045833         1.1   \n",
      "2015-01-04  Atlanta         KATL      1/4/2015    14.279167         6.7   \n",
      "2015-01-03  Atlanta         KATL      1/3/2015    11.154167         8.9   \n",
      "2015-01-02  Atlanta         KATL      1/2/2015     8.116667         6.7   \n",
      "2015-01-01  Atlanta         KATL      1/1/2015     6.758333         0.0   \n",
      "\n",
      "            temp_max_c    state  region missing  \n",
      "date                                             \n",
      "2021-04-20        23.3  Georgia       6       0  \n",
      "2021-04-19        21.7  Georgia       6       0  \n",
      "2021-04-18        22.2  Georgia       6       0  \n",
      "2021-04-17        21.7  Georgia       6       0  \n",
      "2021-04-16        19.4  Georgia       6       0  \n",
      "...                ...      ...     ...     ...  \n",
      "2015-01-05         8.9  Georgia       6       0  \n",
      "2015-01-04        17.8  Georgia       6       0  \n",
      "2015-01-03        16.1  Georgia       6       0  \n",
      "2015-01-02         9.4  Georgia       6       0  \n",
      "2015-01-01        13.9  Georgia       6       0  \n",
      "\n",
      "[2287 rows x 9 columns]\n",
      "<ipython-input-52-44271ce647e7>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  KATL['missing'] = '0'\n"
     ]
    }
   ],
   "source": [
    "# Add column indicating if data was missing\n",
    "KATL['missing'] = '0'\n",
    "print(KATL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "           location_date missing     name  region    state station_code  \\\n",
      "2015-01-01      1/1/2015       0  Atlanta     6.0  Georgia         KATL   \n",
      "2015-01-02      1/2/2015       0  Atlanta     6.0  Georgia         KATL   \n",
      "2015-01-03      1/3/2015       0  Atlanta     6.0  Georgia         KATL   \n",
      "2015-01-04      1/4/2015       0  Atlanta     6.0  Georgia         KATL   \n",
      "2015-01-05      1/5/2015       0  Atlanta     6.0  Georgia         KATL   \n",
      "...                  ...     ...      ...     ...      ...          ...   \n",
      "2021-04-16     4/16/2021       0  Atlanta     6.0  Georgia         KATL   \n",
      "2021-04-17     4/17/2021       0  Atlanta     6.0  Georgia         KATL   \n",
      "2021-04-18     4/18/2021       0  Atlanta     6.0  Georgia         KATL   \n",
      "2021-04-19     4/19/2021       0  Atlanta     6.0  Georgia         KATL   \n",
      "2021-04-20     4/20/2021       0  Atlanta     6.0  Georgia         KATL   \n",
      "\n",
      "            temp_max_c  temp_mean_c  temp_min_c  \n",
      "2015-01-01        13.9     6.758333         0.0  \n",
      "2015-01-02         9.4     8.116667         6.7  \n",
      "2015-01-03        16.1    11.154167         8.9  \n",
      "2015-01-04        17.8    14.279167         6.7  \n",
      "2015-01-05         8.9     5.045833         1.1  \n",
      "...                ...          ...         ...  \n",
      "2021-04-16        19.4    14.695833        10.0  \n",
      "2021-04-17        21.7    16.795833        12.8  \n",
      "2021-04-18        22.2    16.720833        11.7  \n",
      "2021-04-19        21.7    16.154167        11.1  \n",
      "2021-04-20        23.3    17.491667        12.2  \n",
      "\n",
      "[2302 rows x 9 columns]\n",
      "<ipython-input-53-3dd97330f7aa>:3: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  sTime = pd.Series(index=time)\n"
     ]
    }
   ],
   "source": [
    "# Add missing dates to station sub-frame\n",
    "time = pd.date_range(start = '2015-01-01', end = '2021-04-20', freq='D' )\n",
    "sTime = pd.Series(index=time)\n",
    "KATL = pd.concat([KATL, sTime[~sTime.index.isin(KATL.index)]]).sort_index()\n",
    "KATL = KATL.drop([0],axis=1)\n",
    "\n",
    "print(KATL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                    location_date missing name  region state station_code  \\\n2015-03-08 00:00:00           NaN     NaN  NaN     NaN   NaN          NaN   \n2015-11-01 00:00:00           NaN     NaN  NaN     NaN   NaN          NaN   \n2016-03-13 00:00:00           NaN     NaN  NaN     NaN   NaN          NaN   \n2016-11-06 00:00:00           NaN     NaN  NaN     NaN   NaN          NaN   \n2017-03-12 00:00:00           NaN     NaN  NaN     NaN   NaN          NaN   \n2017-09-16 00:00:00           NaN     NaN  NaN     NaN   NaN          NaN   \n2017-11-05 00:00:00           NaN     NaN  NaN     NaN   NaN          NaN   \n2018-03-11 00:00:00           NaN     NaN  NaN     NaN   NaN          NaN   \n2018-11-04 00:00:00           NaN     NaN  NaN     NaN   NaN          NaN   \n2018-12-12 00:00:00           NaN     NaN  NaN     NaN   NaN          NaN   \n2019-03-10 00:00:00           NaN     NaN  NaN     NaN   NaN          NaN   \n2019-11-03 00:00:00           NaN     NaN  NaN     NaN   NaN          NaN   \n2020-03-08 00:00:00           NaN     NaN  NaN     NaN   NaN          NaN   \n2020-11-01 00:00:00           NaN     NaN  NaN     NaN   NaN          NaN   \n2021-03-14 00:00:00           NaN     NaN  NaN     NaN   NaN          NaN   \n\n                     temp_max_c  temp_mean_c  temp_min_c  \n2015-03-08 00:00:00         NaN          NaN         NaN  \n2015-11-01 00:00:00         NaN          NaN         NaN  \n2016-03-13 00:00:00         NaN          NaN         NaN  \n2016-11-06 00:00:00         NaN          NaN         NaN  \n2017-03-12 00:00:00         NaN          NaN         NaN  \n2017-09-16 00:00:00         NaN          NaN         NaN  \n2017-11-05 00:00:00         NaN          NaN         NaN  \n2018-03-11 00:00:00         NaN          NaN         NaN  \n2018-11-04 00:00:00         NaN          NaN         NaN  \n2018-12-12 00:00:00         NaN          NaN         NaN  \n2019-03-10 00:00:00         NaN          NaN         NaN  \n2019-11-03 00:00:00         NaN          NaN         NaN  \n2020-03-08 00:00:00         NaN          NaN         NaN  \n2020-11-01 00:00:00         NaN          NaN         NaN  \n2021-03-14 00:00:00         NaN          NaN         NaN  \n"
     ]
    }
   ],
   "source": [
    "# Flag missing dates as missing\n",
    "\n",
    "# Find rows where data is missing\n",
    "missingKATL = KATL.loc[KATL['missing']!= '0']\n",
    "\n",
    "print(missingKATL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2015-01-01     0.0\n2015-01-02     6.7\n2015-01-03     8.9\n2015-01-04     6.7\n2015-01-05     1.1\n              ... \n2021-04-16    10.0\n2021-04-17    12.8\n2021-04-18    11.7\n2021-04-19    11.1\n2021-04-20    12.2\nName: temp_min_c, Length: 2302, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Interpolate temp_min_c within KATL set \n",
    "KATLinterpolMIN = KATL['temp_min_c'].interpolate()\n",
    "print(KATLinterpolMIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2015-01-01    13.9\n2015-01-02     9.4\n2015-01-03    16.1\n2015-01-04    17.8\n2015-01-05     8.9\n              ... \n2021-04-16    19.4\n2021-04-17    21.7\n2021-04-18    22.2\n2021-04-19    21.7\n2021-04-20    23.3\nName: temp_max_c, Length: 2302, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Interpolate temp_max_c within KATL set \n",
    "KATLinterpolMAX = KATL['temp_max_c'].interpolate()\n",
    "print(KATLinterpolMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2015-01-01     6.758333\n2015-01-02     8.116667\n2015-01-03    11.154167\n2015-01-04    14.279167\n2015-01-05     5.045833\n                ...    \n2021-04-16    14.695833\n2021-04-17    16.795833\n2021-04-18    16.720833\n2021-04-19    16.154167\n2021-04-20    17.491667\nName: temp_mean_c, Length: 2302, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Interpolate temp_mean_c within KATL set \n",
    "KATLinterpolMEAN = KATL['temp_mean_c'].interpolate()\n",
    "print(KATLinterpolMEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate sub-frames with interpolated temperature data into single frame\n",
    "KATLinterpol = pd.concat([KATLinterpolMAX, KATLinterpolMIN, KATLinterpolMEAN], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            temp_mean_c  temp_min_c  temp_max_c\n2015-01-01     6.758333         0.0        13.9\n2015-01-02     8.116667         6.7         9.4\n2015-01-03    11.154167         8.9        16.1\n2015-01-04    14.279167         6.7        17.8\n2015-01-05     5.045833         1.1         8.9\n...                 ...         ...         ...\n2021-04-16    14.695833        10.0        19.4\n2021-04-17    16.795833        12.8        21.7\n2021-04-18    16.720833        11.7        22.2\n2021-04-19    16.154167        11.1        21.7\n2021-04-20    17.491667        12.2        23.3\n\n[2302 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create new df\n",
    "df3 = []\n",
    "# Insert timeseries as index\n",
    "df3 = pd.DataFrame(s)\n",
    "# Concatenate station frame and interpolated temperature data for station frame\n",
    "df3 = pd.concat([KATLinterpolMEAN, KATLinterpolMIN, KATLinterpolMAX], axis=1)\n",
    "# Remove duplicate columns\n",
    "\n",
    "\"\"\" df3 = df3.T.drop_duplicates().T \"\"\"\n",
    "\n",
    "print(df3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add station code column populated with current station\n",
    "KATLinterpol['station_code'] = stations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to add missing dates to entire dataframe with values as nan - Doesn't work\n",
    "time = pd.date_range(start = '2015-01-01', end = '2021-04-20', freq='D' )\n",
    "sTime = pd.Series(index=time)\n",
    "df2 = pd.concat([df2, sTime[~sTime.index.isin(df2.index)]]).sort_index()\n",
    "df2 = df2.drop([0],axis=1)\n",
    "\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd0e96f6acdfbe39255c7875dee1b1acc7feafbd646fa220a924b021b041aac88e9",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
