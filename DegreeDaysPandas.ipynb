{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778d8022-686e-4c94-97f5-edba18938dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1054e409-1f25-48b0-aab0-5ade1936f2d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2bcd91-a1ca-42ec-937c-896df0c9dead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import temperature and population files\n",
    "df = pd.read_csv('../SynMax/Population Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069cc539-c615-4a67-8348-444819ffac30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import temperature and population files\n",
    "df2 = pd.read_csv('../Synmax/Temperature Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create time series including all relevant dates\n",
    "time = pd.date_range(start = '2015-01-01', end = '2021-04-20', freq='D' )\n",
    "s = pd.Series(index=time)\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import temperature and population files\n",
    "# Sanitize temp data\n",
    "    # Convert location_date to datetime\n",
    "    # Set datettime as index\n",
    "        # Iterate through stations one by one to find station's missing days\n",
    "            # Find missing days\n",
    "            # Iterate through missing dates\n",
    "                # Add date row\n",
    "                # Add other relevant info - station_code, region, etc\n",
    "                # Add boolean column indicating interpolated row\n",
    "                # Interpolate temperatures linearly from previous and next day from same station\n",
    "                # Weigh city temp entries by population versus entire region\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cd52ee-e2d5-421a-a3a9-8367e3023f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset grouped by date and name\n",
    "df2bydate = df2.groupby(['location_date', 'name'])[['temp_mean_c', 'temp_min_c', 'temp_max_c']].agg(np.mean)\n",
    "print(df2bydate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame rearranged by date \n",
    "datetime = pd.to_datetime(df2['location_date'])\n",
    "df2['date'] = datetime.dt.date\n",
    "df2 = df2.set_index(\"date\")\n",
    "\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for number of city names in temp data\n",
    "cnt2 = 0\n",
    "cities2 = []\n",
    "for i in range(0, len(df2)):\n",
    "    if df2['name'][i] not in cities2:\n",
    "        cities2.append(df2['name'][i])\n",
    "        cnt2 += 1\n",
    "\n",
    "print(\"No of cities:\", cnt2)\n",
    "print(\"Cities:\", cities2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for unique cities in pop data\n",
    "cnt1 = 0\n",
    "cities1 = []\n",
    "for i in range(0, len(df)):\n",
    "    if df['City'][i] not in cities1:\n",
    "        cities1.append(df['City'][i])\n",
    "        cnt1 += 1\n",
    "\n",
    "print(\"No of unique cities:\", cnt1)\n",
    "print(\"Cities:\", cities1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the country into regions\n",
    "Pacific = ['Washington', 'Oregon', 'California', 'Hawaii', 'Alaska']\n",
    "Mountain = ['Montana', 'Idaho', 'Wyoming', 'Colorado', 'Utah', 'Nevada', 'Arizona', 'New Mexico']\n",
    "WestNorthCentral = ['North Dakota', 'South Dakota', 'Nebraska', 'Kansas', 'Minnesota', 'Iowa', 'Missouri']\n",
    "WestSouthCentral = ['Texas', 'Oklahoma', 'Arkansas', 'Louisiana']\n",
    "EastNorthCentral = ['Michigan', 'Wisconsin', 'Illinois', 'Indiana', 'Ohio']\n",
    "EastSouthCentral = ['Kentucky', 'Tennessee', 'Mississippi', 'Alabama']\n",
    "SouthAtlantic = ['Florida', 'Georgia', 'South Carolina', 'North Carolina', 'Virginia', 'West Virginia', 'Maryland', 'Delaware', 'District of Columbia']\n",
    "MidAtlantic = ['Pennsylvania', 'New York', 'New Jersey']\n",
    "NorthAtlantic = ['Maine', 'Vermont', 'New Hampshire', 'Massachusetts', 'Connecticut', 'Rhode Island']\n",
    "\n",
    "statecount = len(Pacific) + len(Mountain) + len(WestNorthCentral) + len(WestSouthCentral) + len(EastNorthCentral) + len(EastSouthCentral) + len(SouthAtlantic) + len(MidAtlantic) + len(NorthAtlantic)\n",
    "\n",
    "print(statecount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [Pacific, Mountain, WestNorthCentral, WestSouthCentral, EastNorthCentral, EastSouthCentral, SouthAtlantic, MidAtlantic, NorthAtlantic]\n",
    "print(regions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate city names with different station code - 39 stations 38 cities # KPDX Portland Oregon and KPWM Portland Maine\n",
    "cnt3 = 0\n",
    "stations = []\n",
    "for i in range(0, len(df2)):\n",
    "    if df2['station_code'][i] not in stations:\n",
    "        stations.append(df2['station_code'][i])\n",
    "        cnt3 += 1\n",
    "\n",
    "print(\"No of unique stations:\", cnt3)\n",
    "print(\"Stations:\", stations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign states to stations\n",
    "df2.loc[df2['station_code']== 'KBDL', ['state']] = 'Connecticut'\n",
    "df2.loc[df2['station_code']== 'KATL', ['state']] = 'Georgia'\n",
    "df2.loc[df2['station_code']== 'KBNA', ['state']] = 'Tennessee'\n",
    "df2.loc[df2['station_code']== 'KBOI', ['state']] = 'Idaho'\n",
    "df2.loc[df2['station_code']== 'KBOS', ['state']] = 'Massachusetts'\n",
    "df2.loc[df2['station_code']== 'KBUF', ['state']] = 'New York'\n",
    "df2.loc[df2['station_code']== 'KBUR', ['state']] = 'California'\n",
    "df2.loc[df2['station_code']== 'KBWI', ['state']] = 'Maryland'\n",
    "df2.loc[df2['station_code']== 'KCMH', ['state']] = 'Ohio'\n",
    "df2.loc[df2['station_code']== 'KCQT', ['state']] = 'California'\n",
    "df2.loc[df2['station_code']== 'KCVG', ['state']] = 'Kentucky'\n",
    "df2.loc[df2['station_code']== 'KDCA', ['state']] = 'Virginia'\n",
    "df2.loc[df2['station_code']== 'KDEN', ['state']] = 'Colorado'\n",
    "df2.loc[df2['station_code']== 'KDFW', ['state']] = 'Texas'\n",
    "df2.loc[df2['station_code']== 'KDTW', ['state']] = 'Michigan'\n",
    "df2.loc[df2['station_code']== 'KFAT', ['state']] = 'California'\n",
    "df2.loc[df2['station_code']== 'KGEG', ['state']] = 'Washington'\n",
    "df2.loc[df2['station_code']== 'KIAD', ['state']] = 'Virginia'\n",
    "df2.loc[df2['station_code']== 'KIAH', ['state']] = 'Texas'\n",
    "df2.loc[df2['station_code']== 'KLAS', ['state']] = 'Nevada'\n",
    "df2.loc[df2['station_code']== 'KLGA', ['state']] = 'New York'\n",
    "df2.loc[df2['station_code']== 'KLIT', ['state']] = 'Arkansas'\n",
    "df2.loc[df2['station_code']== 'KMEM', ['state']] = 'Tennessee'\n",
    "df2.loc[df2['station_code']== 'KMSP', ['state']] = 'Minnesota'\n",
    "df2.loc[df2['station_code']== 'KMSY', ['state']] = 'Louisiana'\n",
    "df2.loc[df2['station_code']== 'KORD', ['state']] = 'Illinois'\n",
    "df2.loc[df2['station_code']== 'KPDX', ['state']] = 'Oregon'\n",
    "df2.loc[df2['station_code']== 'KPHL', ['state']] = 'Pennsylvania'\n",
    "df2.loc[df2['station_code']== 'KPHX', ['state']] = 'Arizona'\n",
    "df2.loc[df2['station_code']== 'KPIT', ['state']] = 'Pennsylvania'\n",
    "df2.loc[df2['station_code']== 'KPWM', ['state']] = 'Maine'\n",
    "df2.loc[df2['station_code']== 'KRDU', ['state']] = 'North Carolina'\n",
    "df2.loc[df2['station_code']== 'KRIC', ['state']] = 'Virginia'\n",
    "df2.loc[df2['station_code']== 'KSAC', ['state']] = 'California'\n",
    "df2.loc[df2['station_code']== 'KSEA', ['state']] = 'Washington'\n",
    "df2.loc[df2['station_code']== 'KSFO', ['state']] = 'California'\n",
    "df2.loc[df2['station_code']== 'KSLC', ['state']] = 'Utah'\n",
    "df2.loc[df2['station_code']== 'KSTL', ['state']] = 'Missouri'\n",
    "df2.loc[df2['station_code']== 'KALB', ['state']] = 'New York'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Assign states to regions in temperature dataset\n",
    "\n",
    "region = []\n",
    "for i in range(0, len(df2)):\n",
    "    for j in range(0, len(regions)):\n",
    "        if df2['state'][i] in regions[j]:\n",
    "            region.append(j)\n",
    "# Establish region column in temp table      \n",
    "df2[\"region\"] = region  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign states to regions in population dataset\n",
    "\n",
    "region2 = []\n",
    "for k in range(0, len(df)):\n",
    "    for l in range(0, len(regions)):\n",
    "        if df['State'][k] in regions[l]:\n",
    "            region2.append(l)\n",
    "\n",
    "# Establish region column in pop table          \n",
    "df[\"region\"] = region2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframes as .csv\n",
    "df2.to_csv(path_or_buf='../SynMax/Temp Data.csv')\n",
    "df.to_csv(path_or_buf='../SynMax/Pop Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert date to datetime and fill\n",
    "datetime = pd.to_datetime(df2['location_date'])\n",
    "df2['date'] = datetime.dt.date\n",
    "df2 = df2.set_index(\"date\")\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sub-frame of each specific station\n",
    "KATL = df2.loc[df2['station_code'] == stations[0]]\n",
    "KBDL = df2.loc[df2['station_code'] == stations[1]]\n",
    "KBNA = df2.loc[df2['station_code'] == stations[2]]\n",
    "KBOI = df2.loc[df2['station_code'] == stations[3]]\n",
    "KBOS = df2.loc[df2['station_code'] == stations[4]]\n",
    "KBUF = df2.loc[df2['station_code'] == stations[5]]\n",
    "KBUR = df2.loc[df2['station_code'] == stations[6]]\n",
    "KBWI = df2.loc[df2['station_code'] == stations[7]]\n",
    "KCMH = df2.loc[df2['station_code'] == stations[8]]\n",
    "KCQT = df2.loc[df2['station_code'] == stations[9]]\n",
    "KCVG = df2.loc[df2['station_code'] == stations[10]]\n",
    "KDCA = df2.loc[df2['station_code'] == stations[11]]\n",
    "KDEN = df2.loc[df2['station_code'] == stations[12]]\n",
    "KDFW = df2.loc[df2['station_code'] == stations[13]]\n",
    "KDTW = df2.loc[df2['station_code'] == stations[14]]\n",
    "KFAT = df2.loc[df2['station_code'] == stations[15]]\n",
    "KGEG = df2.loc[df2['station_code'] == stations[16]]\n",
    "KIAD = df2.loc[df2['station_code'] == stations[17]]\n",
    "KIAH = df2.loc[df2['station_code'] == stations[18]]\n",
    "KLAS = df2.loc[df2['station_code'] == stations[19]]\n",
    "KLGA = df2.loc[df2['station_code'] == stations[20]]\n",
    "KLIT = df2.loc[df2['station_code'] == stations[21]]\n",
    "KMEM = df2.loc[df2['station_code'] == stations[22]]\n",
    "KMSP = df2.loc[df2['station_code'] == stations[23]]\n",
    "KMSY = df2.loc[df2['station_code'] == stations[24]]\n",
    "KORD = df2.loc[df2['station_code'] == stations[25]]\n",
    "KPDX = df2.loc[df2['station_code'] == stations[26]]\n",
    "KPHL = df2.loc[df2['station_code'] == stations[27]]\n",
    "KPHX = df2.loc[df2['station_code'] == stations[28]]\n",
    "KPIT = df2.loc[df2['station_code'] == stations[29]]\n",
    "KPWM = df2.loc[df2['station_code'] == stations[30]]\n",
    "KRDU = df2.loc[df2['station_code'] == stations[31]]\n",
    "KRIC = df2.loc[df2['station_code'] == stations[32]]\n",
    "KSAC = df2.loc[df2['station_code'] == stations[33]]\n",
    "KSEA = df2.loc[df2['station_code'] == stations[34]]\n",
    "KSFO = df2.loc[df2['station_code'] == stations[35]]\n",
    "KSLC = df2.loc[df2['station_code'] == stations[36]]\n",
    "KSTL = df2.loc[df2['station_code'] == stations[37]]\n",
    "KALB = df2.loc[df2['station_code'] == stations[38]]\n",
    "print(KALB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column indicating if data was missing\n",
    "KATL['missing'] = '0'\n",
    "print(KATL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "           location_date     name  region    state station_code  temp_max_c  \\\n",
      "2015-01-01      1/1/2015  Atlanta     6.0  Georgia         KATL        13.9   \n",
      "2015-01-02      1/2/2015  Atlanta     6.0  Georgia         KATL         9.4   \n",
      "2015-01-03      1/3/2015  Atlanta     6.0  Georgia         KATL        16.1   \n",
      "2015-01-04      1/4/2015  Atlanta     6.0  Georgia         KATL        17.8   \n",
      "2015-01-05      1/5/2015  Atlanta     6.0  Georgia         KATL         8.9   \n",
      "...                  ...      ...     ...      ...          ...         ...   \n",
      "2021-04-16     4/16/2021  Atlanta     6.0  Georgia         KATL        19.4   \n",
      "2021-04-17     4/17/2021  Atlanta     6.0  Georgia         KATL        21.7   \n",
      "2021-04-18     4/18/2021  Atlanta     6.0  Georgia         KATL        22.2   \n",
      "2021-04-19     4/19/2021  Atlanta     6.0  Georgia         KATL        21.7   \n",
      "2021-04-20     4/20/2021  Atlanta     6.0  Georgia         KATL        23.3   \n",
      "\n",
      "            temp_mean_c  temp_min_c  \n",
      "2015-01-01     6.758333         0.0  \n",
      "2015-01-02     8.116667         6.7  \n",
      "2015-01-03    11.154167         8.9  \n",
      "2015-01-04    14.279167         6.7  \n",
      "2015-01-05     5.045833         1.1  \n",
      "...                 ...         ...  \n",
      "2021-04-16    14.695833        10.0  \n",
      "2021-04-17    16.795833        12.8  \n",
      "2021-04-18    16.720833        11.7  \n",
      "2021-04-19    16.154167        11.1  \n",
      "2021-04-20    17.491667        12.2  \n",
      "\n",
      "[2302 rows x 8 columns]\n",
      "<ipython-input-312-3dd97330f7aa>:3: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  sTime = pd.Series(index=time)\n"
     ]
    }
   ],
   "source": [
    "# Add missing dates to station sub-frame\n",
    "time = pd.date_range(start = '2015-01-01', end = '2021-04-20', freq='D' )\n",
    "sTime = pd.Series(index=time)\n",
    "KATL = pd.concat([KATL, sTime[~sTime.index.isin(KATL.index)]]).sort_index()\n",
    "KATL = KATL.drop([0],axis=1)\n",
    "\n",
    "print(KATL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag missing dates as missing\n",
    "\n",
    "# Find rows where data is missing\n",
    "missingKATL = KATL.loc[KATL['missing'].isna() ]\n",
    "\n",
    "# Set values in missing subset \n",
    "# Set missing to 1\n",
    "missingKATL.loc[:,'missing'] = '1'\n",
    "\n",
    "# Set name to station name\n",
    "missingKATL.loc[:, 'name'] = 'Atlanta'\n",
    "\n",
    "# Set region to station region\n",
    "missingKATL.loc[:, 'region'] = '6'\n",
    "\n",
    "# Set state to station state\n",
    "missingKATL.loc[:, 'state'] = 'Georgia'\n",
    "\n",
    "# Set station_code to station\n",
    "missingKATL.loc[:, 'station_code'] = 'KATL'\n",
    "\n",
    "# Remove empty columns of temp data\n",
    "missingKATL.drop(columns=['temp_min_c', 'temp_mean_c', 'temp_max_c', 'location_date'], inplace=True, axis=0)\n",
    "\n",
    "print(missingKATL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpolate temp_min_c within KATL set \n",
    "KATLinterpolMIN = KATL['temp_min_c'].interpolate()\n",
    "print(KATLinterpolMIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpolate temp_max_c within KATL set \n",
    "KATLinterpolMAX = KATL['temp_max_c'].interpolate()\n",
    "print(KATLinterpolMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpolate temp_mean_c within KATL set \n",
    "KATLinterpolMEAN = KATL['temp_mean_c'].interpolate()\n",
    "print(KATLinterpolMEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate sub-frames of interpolated temperature data into single frame\n",
    "KATLinterpol = pd.concat([KATLinterpolMAX, KATLinterpolMIN, KATLinterpolMEAN], axis=1)\n",
    "\n",
    "print(KATLinterpol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new empty frame and integrate missing date row frames with interpolated temp frame\n",
    "KATL2 = []\n",
    "KATL2 = pd.DataFrame(s)\n",
    "KATL2 = pd.concat([KATLinterpol, missingKATL], axis=1)\n",
    "KATL2 = KATL2.dropna()\n",
    "print(KATL2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all NaN rows from original station subframe and combine cleaned and interpolated subframes\n",
    "KATL = KATL.dropna()\n",
    "KATL3 = pd.concat([KATL, KATL2], axis=0)\n",
    "# Review complete sub-frame of KATL \n",
    "print(KATL3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column indicating if data was missing\n",
    "KSTL['missing'] = False\n",
    "\n",
    "# Add missing dates to station sub-frame\n",
    "time = pd.date_range(start = '2015-01-01', end = '2021-04-20', freq='D' )\n",
    "sTime = pd.Series(index=time)\n",
    "KSTL = pd.concat([KSTL, sTime[~sTime.index.isin(KSTL.index)]]).sort_index()\n",
    "KSTL = KSTL.drop([0],axis=1)\n",
    "\n",
    "# Find rows where data is missing\n",
    "missingKSTL = KSTL.loc[KSTL['missing'].isna() ]\n",
    "# Set values in missing subset \n",
    "# Set missing to 1\n",
    "missingKSTL.loc[:,'missing'] = True\n",
    "\n",
    "# Set name to station name\n",
    "missingKSTL.loc[:, 'name'] = 'St Louis/Lambert'\n",
    "\n",
    "# Set region to station region\n",
    "missingKSTL.loc[:, 'region'] = '2'\n",
    "\n",
    "# Set state to station state\n",
    "missingKSTL.loc[:, 'state'] = 'Missouri'\n",
    "\n",
    "# Set station_code to station\n",
    "missingKSTL.loc[:, 'station_code'] = 'KSTL'\n",
    "\n",
    "# Remove empty columns of temp data\n",
    "missingKSTL.drop(columns=['temp_min_c', 'temp_mean_c', 'temp_max_c', 'location_date'], inplace=True, axis=0)\n",
    "\n",
    "#Interpolate temp_min_c within KSTL set \n",
    "KSTLinterpolMIN = KSTL['temp_min_c'].interpolate()\n",
    "\n",
    "#Interpolate temp_max_c within KSTL set \n",
    "KSTLinterpolMAX = KSTL['temp_max_c'].interpolate()\n",
    "\n",
    "#Interpolate temp_mean_c within KSTL set \n",
    "KSTLinterpolMEAN = KSTL['temp_mean_c'].interpolate()\n",
    "\n",
    "# Concatenate sub-frames of interpolated temperature data into single frame\n",
    "KSTLinterpol = pd.concat([KSTLinterpolMAX, KSTLinterpolMIN, KSTLinterpolMEAN], axis=1)\n",
    "\n",
    "# Create new empty frame and integrate missing date row frames with interpolated temp frame\n",
    "KSTL2 = []\n",
    "KSTL2 = pd.DataFrame(s)\n",
    "KSTL2 = pd.concat([KSTLinterpol, missingKSTL], axis=1)\n",
    "KSTL2 = KSTL2.dropna()\n",
    "\n",
    "# Drop all NaN rows from original station subframe and combine cleaned and interpolated subframes\n",
    "KSTL = KSTL.dropna()\n",
    "KSTL3 = pd.concat([KSTL, KSTL2], axis=0)\n",
    "# Review complete sub-frame of KSTL \n",
    "print(KSTL3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append all wrangled station dataframes into one\n",
    "df3 = pd.DataFrame(KATL3)\n",
    "\n",
    "df3 = pd.concat([df3, KBDL3, KBNA3, KBOI3, KBOS3, KBUF3, KBUR3, KBWI3, KCMH3, KCQT3], axis=0)\n",
    "df3 = pd.concat([df3, KDCA3, KDEN3, KDFW3, KDTW3, KFAT3, KGEG3, KIAD3, KIAH3, KLAS3], axis=0)\n",
    "df3 = pd.concat([df3, KLIT3, KMEM3, KMSP3, KMSY3, KORD3, KPDX3, KPHL3, KPHX3, KPIT3], axis=0)\n",
    "df3 = pd.concat([df3, KRDU3, KRIC3, KSAC3, KSEA3, KSFO3, KSLC3, KSTL3, KALB3, KCVG3], axis=0)\n",
    "df3 = pd.concat([df3, KPWM3, KLGA3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv(path_or_buf='../SynMax/Temp Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWeights = pd.DataFrame(s)\n",
    "print(dfWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a population weighted daily temperature timeseries - Population data is old and inaccurate \n",
    "    # Add population column to stations - \n",
    "    # Albany (97,879 in 2011), Covington (use Cincinnati population), Portland Maine (66240 in 2011), Windsor Locks (12498 in 2010 census) missing from pop data\n",
    "    # Las Vegas AND North Las Vegas present in pop data (Las Vegas metro area population MUCH larger than either one listed in given table)\n",
    "    # Raleigh and Durham present in pop data\n",
    "    # St Louis vs St. Louis\n",
    "    # Nearby stations - Divide population by two to give equal weight to both stations in the area\n",
    "        # Washington vs Wash DC/Dulles, KDCA (Arlington Virginia) and KIAD (Dulles, VA)\n",
    "        # Burbank vs Los Angeles\n",
    "        # Las Vegas vs North Las Vegas\n",
    "        \n",
    "    # Create regional weight column \n",
    "    # Create national weight column \n",
    "    # Weight of station within region vs other stations - Average regional min, max, mean of any particular day\n",
    "    # Weight of station within country vs other stations - Average national min, max, mean of any particular day\n",
    "    # Create seasonal average column\n",
    "    # Create seasonal high column\n",
    "    # Create seasonal low column\n",
    "    # Create monthly high column\n",
    "    # Create monthly low column\n",
    "    # Create monthly mean column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Someone who wants to know how the temperature compares to the seasonal average as well as high and low cases. \n",
    "\n",
    "# 2 Someone who wants to view the monthly average, min and max. \n",
    "\n",
    "# 3 Someone who wants to graphically see what data is missing or projected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are 4 ways to select all rows with NaN values in Pandas DataFrame:\n",
    "\n",
    "# (1) Using isna() to select all rows with NaN under a single DataFrame column:\n",
    "# df[df['column name'].isna()]\n",
    "\n",
    "# (2) Using isnull() to select all rows with NaN under a single DataFrame column:\n",
    "# df[df['column name'].isnull()]\n",
    "\n",
    "# (3) Using isna() to select all rows with NaN under an entire DataFrame:\n",
    "# df[df.isna().any(axis=1)]\n",
    "\n",
    "# (4) Using isnull() to select all rows with NaN under an entire DataFrame:\n",
    "# df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subframe with population data and weights for calculations\n",
    "\n",
    "type(stations)\n",
    "\n",
    "dfStations = pd.DataFrame(stations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfStations['population'] = 0\n",
    "dfStations['nationalweight'] = 0\n",
    "dfStations['regionalweight'] = 0\n",
    "\n",
    "print(dfStations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       0  population  nationalweight  regionalweight\n0   KATL     5162000               0               0\n1   KBDL     1211324               0               0\n2   KBNA     1775583               0               0\n3   KBOI      399000               0               0\n4   KBOS     4261000               0               0\n5   KBUF      259517               0               0\n6   KBUR     6172500               0               0\n7   KBWI     2790053               0               0\n8   KCMH     1510000               0               0\n9   KCQT     6172500               0               0\n10  KCVG     1693000               0               0\n11  KDCA     3050000               0               0\n12  KDEN     2608000               0               0\n13  KDFW     5723000               0               0\n14  KDTW     3648000               0               0\n15  KFAT      714000               0               0\n16  KGEG      419000               0               0\n17  KIAD     3050000               0               0\n18  KIAH     5660000               0               0\n19  KLAS     2280000               0               0\n20  KLGA    18648000               0               0\n21  KLIT      474000               0               0\n22  KMEM     1109000               0               0\n23  KMSP     2800000               0               0\n24  KMSY      950000               0               0\n25  KORD     8770000               0               0\n26  KPDX     2008000               0               0\n27  KPHL     5602000               0               0\n28  KPHX     4077000               0               0\n29  KPIT     1724000               0               0\n30  KPWM       66490               0               0\n31  KRDU     1145000               0               0\n32  KRIC     1033000               0               0\n33  KSAC     1927000               0               0\n34  KSEA     3259000               0               0\n35  KSFO     3309000               0               0\n36  KSLC     1099000               0               0\n37  KSTL     2190000               0               0\n38  KALB      615000               0               0\n"
     ]
    }
   ],
   "source": [
    "# Add 2015 metropolitan area populations - split populations by two where metropolitan area has two weather stations - www.census.gov & macrotrends.net\n",
    "dfStations.at[0, 'population'] = 5162000\n",
    "dfStations.at[1, 'population'] = 1211324\n",
    "dfStations.at[2, 'population'] = 1775583\n",
    "dfStations.at[3, 'population'] = 399000\n",
    "dfStations.at[4, 'population'] = 4261000\n",
    "dfStations.at[5, 'population'] = 259517\n",
    "dfStations.at[6, 'population'] = 12345000/2\n",
    "dfStations.at[7, 'population'] = 2790053\n",
    "dfStations.at[8, 'population'] = 1510000\n",
    "dfStations.at[9, 'population'] = 12345000/2\n",
    "dfStations.at[10, 'population'] = 1693000\n",
    "dfStations.at[11, 'population'] = 6100000/2\n",
    "dfStations.at[12, 'population'] = 2608000\n",
    "dfStations.at[13, 'population'] = 5723000\n",
    "dfStations.at[14, 'population'] = 3648000\n",
    "dfStations.at[15, 'population'] = 714000\n",
    "dfStations.at[16, 'population'] = 419000\n",
    "dfStations.at[17, 'population'] = 6100000/2\n",
    "dfStations.at[18, 'population'] = 5660000\n",
    "dfStations.at[19, 'population'] = 2280000\n",
    "dfStations.at[20, 'population'] = 18648000\n",
    "dfStations.at[21, 'population'] = 474000\n",
    "dfStations.at[22, 'population'] = 1109000\n",
    "dfStations.at[23, 'population'] = 2800000\n",
    "dfStations.at[24, 'population'] = 950000\n",
    "dfStations.at[25, 'population'] = 8770000\n",
    "dfStations.at[26, 'population'] = 2008000\n",
    "dfStations.at[27, 'population'] = 5602000\n",
    "dfStations.at[28, 'population'] = 4077000\n",
    "dfStations.at[29, 'population'] = 1724000\n",
    "dfStations.at[30, 'population'] = 66490\n",
    "dfStations.at[31, 'population'] = 1145000\n",
    "dfStations.at[32, 'population'] = 1033000\n",
    "dfStations.at[33, 'population'] = 1927000\n",
    "dfStations.at[34, 'population'] = 3259000\n",
    "dfStations.at[35, 'population'] = 3309000\n",
    "dfStations.at[36, 'population'] = 1099000\n",
    "dfStations.at[37, 'population'] = 2190000\n",
    "dfStations.at[38, 'population'] = 615000\n",
    "print(dfStations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "119363967\n"
     ]
    }
   ],
   "source": [
    "totalPop = dfStations['population'].sum()\n",
    "\n",
    "print(totalPop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   station_code  population  nationalweight  regionalweight\n",
       "0          KATL     5162000        0.043246               0\n",
       "1          KBDL     1211324        0.010148               0\n",
       "2          KBNA     1775583        0.014875               0\n",
       "3          KBOI      399000        0.003343               0\n",
       "4          KBOS     4261000        0.035698               0\n",
       "5          KBUF      259517        0.002174               0\n",
       "6          KBUR     6172500        0.051712               0\n",
       "7          KBWI     2790053        0.023374               0\n",
       "8          KCMH     1510000        0.012650               0\n",
       "9          KCQT     6172500        0.051712               0\n",
       "10         KCVG     1693000        0.014184               0\n",
       "11         KDCA     3050000        0.025552               0\n",
       "12         KDEN     2608000        0.021849               0\n",
       "13         KDFW     5723000        0.047946               0\n",
       "14         KDTW     3648000        0.030562               0\n",
       "15         KFAT      714000        0.005982               0\n",
       "16         KGEG      419000        0.003510               0\n",
       "17         KIAD     3050000        0.025552               0\n",
       "18         KIAH     5660000        0.047418               0\n",
       "19         KLAS     2280000        0.019101               0\n",
       "20         KLGA    18648000        0.156228               0\n",
       "21         KLIT      474000        0.003971               0\n",
       "22         KMEM     1109000        0.009291               0\n",
       "23         KMSP     2800000        0.023458               0\n",
       "24         KMSY      950000        0.007959               0\n",
       "25         KORD     8770000        0.073473               0\n",
       "26         KPDX     2008000        0.016822               0\n",
       "27         KPHL     5602000        0.046932               0\n",
       "28         KPHX     4077000        0.034156               0\n",
       "29         KPIT     1724000        0.014443               0\n",
       "30         KPWM       66490        0.000557               0\n",
       "31         KRDU     1145000        0.009593               0\n",
       "32         KRIC     1033000        0.008654               0\n",
       "33         KSAC     1927000        0.016144               0\n",
       "34         KSEA     3259000        0.027303               0\n",
       "35         KSFO     3309000        0.027722               0\n",
       "36         KSLC     1099000        0.009207               0\n",
       "37         KSTL     2190000        0.018347               0\n",
       "38         KALB      615000        0.005152               0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>station_code</th>\n      <th>population</th>\n      <th>nationalweight</th>\n      <th>regionalweight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>KATL</td>\n      <td>5162000</td>\n      <td>0.043246</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>KBDL</td>\n      <td>1211324</td>\n      <td>0.010148</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>KBNA</td>\n      <td>1775583</td>\n      <td>0.014875</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>KBOI</td>\n      <td>399000</td>\n      <td>0.003343</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>KBOS</td>\n      <td>4261000</td>\n      <td>0.035698</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>KBUF</td>\n      <td>259517</td>\n      <td>0.002174</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>KBUR</td>\n      <td>6172500</td>\n      <td>0.051712</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>KBWI</td>\n      <td>2790053</td>\n      <td>0.023374</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>KCMH</td>\n      <td>1510000</td>\n      <td>0.012650</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>KCQT</td>\n      <td>6172500</td>\n      <td>0.051712</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>KCVG</td>\n      <td>1693000</td>\n      <td>0.014184</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>KDCA</td>\n      <td>3050000</td>\n      <td>0.025552</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>KDEN</td>\n      <td>2608000</td>\n      <td>0.021849</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>KDFW</td>\n      <td>5723000</td>\n      <td>0.047946</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>KDTW</td>\n      <td>3648000</td>\n      <td>0.030562</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>KFAT</td>\n      <td>714000</td>\n      <td>0.005982</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>KGEG</td>\n      <td>419000</td>\n      <td>0.003510</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>KIAD</td>\n      <td>3050000</td>\n      <td>0.025552</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>KIAH</td>\n      <td>5660000</td>\n      <td>0.047418</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>KLAS</td>\n      <td>2280000</td>\n      <td>0.019101</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>KLGA</td>\n      <td>18648000</td>\n      <td>0.156228</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>KLIT</td>\n      <td>474000</td>\n      <td>0.003971</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>KMEM</td>\n      <td>1109000</td>\n      <td>0.009291</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>KMSP</td>\n      <td>2800000</td>\n      <td>0.023458</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>KMSY</td>\n      <td>950000</td>\n      <td>0.007959</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>KORD</td>\n      <td>8770000</td>\n      <td>0.073473</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>KPDX</td>\n      <td>2008000</td>\n      <td>0.016822</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>KPHL</td>\n      <td>5602000</td>\n      <td>0.046932</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>KPHX</td>\n      <td>4077000</td>\n      <td>0.034156</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>KPIT</td>\n      <td>1724000</td>\n      <td>0.014443</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>KPWM</td>\n      <td>66490</td>\n      <td>0.000557</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>KRDU</td>\n      <td>1145000</td>\n      <td>0.009593</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>KRIC</td>\n      <td>1033000</td>\n      <td>0.008654</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>KSAC</td>\n      <td>1927000</td>\n      <td>0.016144</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>KSEA</td>\n      <td>3259000</td>\n      <td>0.027303</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>KSFO</td>\n      <td>3309000</td>\n      <td>0.027722</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>KSLC</td>\n      <td>1099000</td>\n      <td>0.009207</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>KSTL</td>\n      <td>2190000</td>\n      <td>0.018347</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>KALB</td>\n      <td>615000</td>\n      <td>0.005152</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 296
    }
   ],
   "source": [
    "dfStations.assign(nationalweight = dfStations['population']/totalPop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   station_code  population  nationalweight  regionalweight\n0          KATL     5162000               0               0\n1          KBDL     1211324               0               0\n2          KBNA     1775583               0               0\n3          KBOI      399000               0               0\n4          KBOS     4261000               0               0\n5          KBUF      259517               0               0\n6          KBUR     6172500               0               0\n7          KBWI     2790053               0               0\n8          KCMH     1510000               0               0\n9          KCQT     6172500               0               0\n10         KCVG     1693000               0               0\n11         KDCA     3050000               0               0\n12         KDEN     2608000               0               0\n13         KDFW     5723000               0               0\n14         KDTW     3648000               0               0\n15         KFAT      714000               0               0\n16         KGEG      419000               0               0\n17         KIAD     3050000               0               0\n18         KIAH     5660000               0               0\n19         KLAS     2280000               0               0\n20         KLGA    18648000               0               0\n21         KLIT      474000               0               0\n22         KMEM     1109000               0               0\n23         KMSP     2800000               0               0\n24         KMSY      950000               0               0\n25         KORD     8770000               0               0\n26         KPDX     2008000               0               0\n27         KPHL     5602000               0               0\n28         KPHX     4077000               0               0\n29         KPIT     1724000               0               0\n30         KPWM       66490               0               0\n31         KRDU     1145000               0               0\n32         KRIC     1033000               0               0\n33         KSAC     1927000               0               0\n34         KSEA     3259000               0               0\n35         KSFO     3309000               0               0\n36         KSLC     1099000               0               0\n37         KSTL     2190000               0               0\n38         KALB      615000               0               0\n"
     ]
    }
   ],
   "source": [
    "dfStations.columns = ['station_code', 'population', 'nationalweight', 'regionalweight']\n",
    "dfStations.assign(nationalweight = dfStations['population']/totalPop)\n",
    "print(dfStations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "totalWeight = dfStations['nationalweight'].sum()\n",
    "print(totalWeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-271-241d53e683cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mweighted_avg_m3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mdf3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'temp_max_c'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfStations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'population'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mweighted_avg_m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36maverage\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36maverage\u001b[1;34m(a, axis, weights, returned)\u001b[0m\n\u001b[0;32m    397\u001b[0m                 raise TypeError(\n\u001b[0;32m    398\u001b[0m                     \"1D weights expected when shapes of a and weights differ.\")\n\u001b[1;32m--> 399\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mwgt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m                 raise ValueError(\n\u001b[0;32m    401\u001b[0m                     \"Length of weights not compatible with specified axis.\")\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# Calculated weighted average national MAX temperature by day\n",
    "\n",
    "\n",
    "\n",
    "weighted_avg_m3 = round(average( df3['temp_max_c'], axis=0, weights = dfStations['population']),2)\n",
    "\n",
    "weighted_avg_m3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv(path_or_buf='../SynMax/Temp Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                            temp_mean_c  temp_min_c  temp_max_c\n",
       "location_date station_code                                     \n",
       "1/1/2015      KALB            -3.362500        -7.2         0.0\n",
       "              KATL             6.758333         0.0        13.9\n",
       "              KBDL            -1.991667        -7.8         1.1\n",
       "              KBNA             1.141667        -5.0         5.0\n",
       "              KBOI           -11.070833       -13.9        -8.0\n",
       "...                                 ...         ...         ...\n",
       "9/9/2020      KSAC            22.829167        17.2        28.9\n",
       "              KSEA            22.816667        15.0        31.7\n",
       "              KSFO            16.304167        15.0        17.8\n",
       "              KSLC            11.416667         6.1        17.2\n",
       "              KSTL            23.937500        19.4        29.4\n",
       "\n",
       "[89219 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>temp_mean_c</th>\n      <th>temp_min_c</th>\n      <th>temp_max_c</th>\n    </tr>\n    <tr>\n      <th>location_date</th>\n      <th>station_code</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">1/1/2015</th>\n      <th>KALB</th>\n      <td>-3.362500</td>\n      <td>-7.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>KATL</th>\n      <td>6.758333</td>\n      <td>0.0</td>\n      <td>13.9</td>\n    </tr>\n    <tr>\n      <th>KBDL</th>\n      <td>-1.991667</td>\n      <td>-7.8</td>\n      <td>1.1</td>\n    </tr>\n    <tr>\n      <th>KBNA</th>\n      <td>1.141667</td>\n      <td>-5.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>KBOI</th>\n      <td>-11.070833</td>\n      <td>-13.9</td>\n      <td>-8.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">9/9/2020</th>\n      <th>KSAC</th>\n      <td>22.829167</td>\n      <td>17.2</td>\n      <td>28.9</td>\n    </tr>\n    <tr>\n      <th>KSEA</th>\n      <td>22.816667</td>\n      <td>15.0</td>\n      <td>31.7</td>\n    </tr>\n    <tr>\n      <th>KSFO</th>\n      <td>16.304167</td>\n      <td>15.0</td>\n      <td>17.8</td>\n    </tr>\n    <tr>\n      <th>KSLC</th>\n      <td>11.416667</td>\n      <td>6.1</td>\n      <td>17.2</td>\n    </tr>\n    <tr>\n      <th>KSTL</th>\n      <td>23.937500</td>\n      <td>19.4</td>\n      <td>29.4</td>\n    </tr>\n  </tbody>\n</table>\n<p>89219 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 304
    }
   ],
   "source": [
    "# Group df3 by station_code\n",
    "df3.groupby(['location_date', 'station_code'])[['temp_mean_c', 'temp_min_c', 'temp_max_c']].agg(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df3.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = pd.Series(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2015-01-01   NaN\n2015-01-02   NaN\n2015-01-03   NaN\n2015-01-04   NaN\n2015-01-05   NaN\n              ..\n2021-04-16   NaN\n2021-04-17   NaN\n2021-04-18   NaN\n2021-04-19   NaN\n2021-04-20   NaN\nFreq: D, Length: 2302, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           location_date missing     name region    state station_code  \\\n",
       "2015-01-01      1/1/2015       0  Atlanta    6.0  Georgia         KATL   \n",
       "2015-01-02      1/2/2015       0  Atlanta    6.0  Georgia         KATL   \n",
       "2015-01-03      1/3/2015       0  Atlanta    6.0  Georgia         KATL   \n",
       "2015-01-04      1/4/2015       0  Atlanta    6.0  Georgia         KATL   \n",
       "2015-01-05      1/5/2015       0  Atlanta    6.0  Georgia         KATL   \n",
       "\n",
       "            temp_max_c  temp_mean_c  temp_min_c  population  nationalweight  \\\n",
       "2015-01-01        13.9     6.758333         0.0           0               0   \n",
       "2015-01-02         9.4     8.116667         6.7           0               0   \n",
       "2015-01-03        16.1    11.154167         8.9           0               0   \n",
       "2015-01-04        17.8    14.279167         6.7           0               0   \n",
       "2015-01-05         8.9     5.045833         1.1           0               0   \n",
       "\n",
       "            regionalweight  NWtempMIN  NWtempMAX  NWtempMEAN  RWtempMIN  \\\n",
       "2015-01-01               0          0          0           0          0   \n",
       "2015-01-02               0          0          0           0          0   \n",
       "2015-01-03               0          0          0           0          0   \n",
       "2015-01-04               0          0          0           0          0   \n",
       "2015-01-05               0          0          0           0          0   \n",
       "\n",
       "            RWtempMAX  RWtempMEAN  \n",
       "2015-01-01          0           0  \n",
       "2015-01-02          0           0  \n",
       "2015-01-03          0           0  \n",
       "2015-01-04          0           0  \n",
       "2015-01-05          0           0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>location_date</th>\n      <th>missing</th>\n      <th>name</th>\n      <th>region</th>\n      <th>state</th>\n      <th>station_code</th>\n      <th>temp_max_c</th>\n      <th>temp_mean_c</th>\n      <th>temp_min_c</th>\n      <th>population</th>\n      <th>nationalweight</th>\n      <th>regionalweight</th>\n      <th>NWtempMIN</th>\n      <th>NWtempMAX</th>\n      <th>NWtempMEAN</th>\n      <th>RWtempMIN</th>\n      <th>RWtempMAX</th>\n      <th>RWtempMEAN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2015-01-01</th>\n      <td>1/1/2015</td>\n      <td>0</td>\n      <td>Atlanta</td>\n      <td>6.0</td>\n      <td>Georgia</td>\n      <td>KATL</td>\n      <td>13.9</td>\n      <td>6.758333</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2015-01-02</th>\n      <td>1/2/2015</td>\n      <td>0</td>\n      <td>Atlanta</td>\n      <td>6.0</td>\n      <td>Georgia</td>\n      <td>KATL</td>\n      <td>9.4</td>\n      <td>8.116667</td>\n      <td>6.7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2015-01-03</th>\n      <td>1/3/2015</td>\n      <td>0</td>\n      <td>Atlanta</td>\n      <td>6.0</td>\n      <td>Georgia</td>\n      <td>KATL</td>\n      <td>16.1</td>\n      <td>11.154167</td>\n      <td>8.9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2015-01-04</th>\n      <td>1/4/2015</td>\n      <td>0</td>\n      <td>Atlanta</td>\n      <td>6.0</td>\n      <td>Georgia</td>\n      <td>KATL</td>\n      <td>17.8</td>\n      <td>14.279167</td>\n      <td>6.7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2015-01-05</th>\n      <td>1/5/2015</td>\n      <td>0</td>\n      <td>Atlanta</td>\n      <td>6.0</td>\n      <td>Georgia</td>\n      <td>KATL</td>\n      <td>8.9</td>\n      <td>5.045833</td>\n      <td>1.1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 302
    }
   ],
   "source": [
    "df3.loc[df3.station_code == 'KATL', :].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weighted daily temperature vs seasonal average, season high, and season low"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "e96f6acdfbe39255c7875dee1b1acc7feafbd646fa220a924b021b041aac88e9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}